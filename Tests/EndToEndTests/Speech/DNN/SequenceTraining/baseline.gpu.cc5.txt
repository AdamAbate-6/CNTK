CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz
    Hardware threads: 12
    Total Memory: 57700428 kB
-------------------------------------------------------------------
=== Running /home/ubuntu/workspace/build/gpu/debug/bin/cntk configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/cntk_sequence.cntk currentDirectory=/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData RunDir=/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu DataDir=/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining OutputDir=/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu DeviceId=0 timestamping=true
CNTK 2.3.1+ (HEAD ed450d, Jan  7 2018 20:10:59) at 2018/01/08 04:59:29

/home/ubuntu/workspace/build/gpu/debug/bin/cntk  configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/cntk_sequence.cntk  currentDirectory=/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData  RunDir=/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu  DataDir=/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData  ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining  OutputDir=/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu  DeviceId=0  timestamping=true
Changed current directory to /tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData
01/08/2018 04:59:29: -------------------------------------------------------------------
01/08/2018 04:59:29: Build info: 

01/08/2018 04:59:29: 		Built time: Jan  7 2018 20:08:47
01/08/2018 04:59:29: 		Last modified date: Sun Jan  7 20:08:19 2018
01/08/2018 04:59:29: 		Build type: debug
01/08/2018 04:59:29: 		Build target: GPU
01/08/2018 04:59:29: 		With 1bit-SGD: no
01/08/2018 04:59:29: 		With ASGD: yes
01/08/2018 04:59:29: 		Math lib: mkl
01/08/2018 04:59:29: 		CUDA version: 9.0.0
01/08/2018 04:59:29: 		CUDNN version: 7.0.4
01/08/2018 04:59:29: 		Build Branch: HEAD
01/08/2018 04:59:29: 		Build SHA1: ed450d284dda1f314dfdeee86ce68e5bbfb0a87f
01/08/2018 04:59:29: 		MPI distribution: Open MPI
01/08/2018 04:59:29: 		MPI version: 1.10.7
01/08/2018 04:59:29: -------------------------------------------------------------------
01/08/2018 04:59:29: -------------------------------------------------------------------
01/08/2018 04:59:29: GPU info:

01/08/2018 04:59:29: 		Device[0]: cores = 3072; computeCapability = 5.2; type = "Tesla M60"; total memory = 8123 MB; free memory = 8112 MB
01/08/2018 04:59:29: -------------------------------------------------------------------

Configuration, Raw:

01/08/2018 04:59:29: precision = "float"
deviceId = $DeviceId$
command = dptPre1:addLayer2:dptPre2:addLayer3:speechTrain:replaceCriterionNode:sequenceTrain
ndlMacros = "$ConfigDir$/macros.txt"
globalMeanPath   = "GlobalStats/mean.363"
globalInvStdPath = "GlobalStats/var.363"
globalPriorPath  = "GlobalStats/prior.132"
traceLevel = 1
truncated = false
SGD = [
    epochSize = 81920
    minibatchSize = 256
    learningRatesPerMB = 0.8
    numMBsToShowResult = 10
    momentumPerMB = 0.9
    dropoutRate = 0.0
    maxEpochs = 2
]
dptPre1 = [
    action = "train"
    modelPath = "$RunDir$/models/Pre1/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "$ConfigDir$/dnn_1layer.txt"
    ]
]
addLayer2 = [    
    action = "edit"
    currLayer = 1
    newLayer = 2
    currModel = "$RunDir$/models/Pre1/cntkSpeech"
    newModel  = "$RunDir$/models/Pre2/cntkSpeech.0"
    editPath  = "$ConfigDir$/add_layer.mel"
]
dptPre2 = [
    action = "train"
    modelPath = "$RunDir$/models/Pre2/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "$ConfigDir$/dnn_1layer.txt"
    ]
]
AddLayer3 = [    
    action = "edit"
    currLayer = 2
    newLayer = 3
    currModel = "$RunDir$/models/Pre2/cntkSpeech"
    newModel  = "$RunDir$/models/cntkSpeech.0"
    editPath  = "$ConfigDir$/add_layer.mel"
]
speechTrain = [
    action = "train"
    modelPath = "$RunDir$/models/cntkSpeech"
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "$ConfigDir$/dnn.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 256:512
        learningRatesPerMB = 0.8:1.6
        numMBsToShowResult = 10
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 4
        gradUpdateType = "none"
        normWithAveMultiplier = true
        clippingThresholdPerSample = 1#INF
    ]
]
reader = [
    readerType = "HTKMLFReader"
    readMethod = "blockRandomize"
    miniBatchMode = "partial"
    randomize = "auto"
    verbosity = 0
    features = [
        dim = 363
        type = "real"
        scpFile = "$DataDir$/glob_0000.scp"
    ]
    labels = [
        mlfFile = "$DataDir$/glob_0000.mlf"
        labelMappingFile = "$DataDir$/state.list"
        labelDim = 132
        labelType = "category"
    ]
]
replaceCriterionNode = [
    action = "edit"
    currModel = "$RunDir$/models/cntkSpeech"
    newModel  = "$RunDir$/models/cntkSpeech.sequence.0"
    editPath  = "$ConfigDir$/replace_ce_with_sequence_criterion.mel"
]
sequenceTrain = [
    action = "train"
    modelPath = "$RunDir$/models/cntkSpeech.sequence"
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "$ConfigDir$/nonexistentfile.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 10
        learningRatesPerSample = 0.000002
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 3
        hsmoothingWeight = 0.95
        frameDropThresh = 1e-10
        numMBsToShowResult = 10
        gradientClippingWithTruncation = true
        clippingThresholdPerSample = 1.0
    ]
    reader = [
        readerType = "HTKMLFReader"
        readMethod = "blockRandomize"
        frameMode = false
        nbruttsineachrecurrentiter = 2
        miniBatchMode = "partial"
        randomize = "auto"
        verbosity = 0
        features = [
            dim = 363
            type = "real"
            scpFile = "$DataDir$/glob_0000.scp"
        ]
        labels = [
            mlfFile = "$DataDir$/glob_0000.mlf"
            labelMappingFile = "$DataDir$/state.list"
            labelDim = 132
            labelType = "category"
        ]
        hmms = [
            phoneFile  = "$DataDir$/model.overalltying"
            transpFile = "$DataDir$/model.transprob"
        ]
        lattices = [
            denlatTocFile = "$DataDir$/*.lats.toc"
        ]
    ]
]
currentDirectory=/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData
RunDir=/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu
DataDir=/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData
ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining
OutputDir=/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu
DeviceId=0
timestamping=true


Configuration After Variable Resolution:

01/08/2018 04:59:29: precision = "float"
deviceId = 0
command = dptPre1:addLayer2:dptPre2:addLayer3:speechTrain:replaceCriterionNode:sequenceTrain
ndlMacros = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/macros.txt"
globalMeanPath   = "GlobalStats/mean.363"
globalInvStdPath = "GlobalStats/var.363"
globalPriorPath  = "GlobalStats/prior.132"
traceLevel = 1
truncated = false
SGD = [
    epochSize = 81920
    minibatchSize = 256
    learningRatesPerMB = 0.8
    numMBsToShowResult = 10
    momentumPerMB = 0.9
    dropoutRate = 0.0
    maxEpochs = 2
]
dptPre1 = [
    action = "train"
    modelPath = "/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/models/Pre1/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/dnn_1layer.txt"
    ]
]
addLayer2 = [    
    action = "edit"
    currLayer = 1
    newLayer = 2
    currModel = "/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/models/Pre1/cntkSpeech"
    newModel  = "/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/models/Pre2/cntkSpeech.0"
    editPath  = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/add_layer.mel"
]
dptPre2 = [
    action = "train"
    modelPath = "/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/models/Pre2/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/dnn_1layer.txt"
    ]
]
AddLayer3 = [    
    action = "edit"
    currLayer = 2
    newLayer = 3
    currModel = "/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/models/Pre2/cntkSpeech"
    newModel  = "/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/models/cntkSpeech.0"
    editPath  = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/add_layer.mel"
]
speechTrain = [
    action = "train"
    modelPath = "/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/models/cntkSpeech"
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/dnn.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 256:512
        learningRatesPerMB = 0.8:1.6
        numMBsToShowResult = 10
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 4
        gradUpdateType = "none"
        normWithAveMultiplier = true
        clippingThresholdPerSample = 1#INF
    ]
]
reader = [
    readerType = "HTKMLFReader"
    readMethod = "blockRandomize"
    miniBatchMode = "partial"
    randomize = "auto"
    verbosity = 0
    features = [
        dim = 363
        type = "real"
        scpFile = "/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData/glob_0000.scp"
    ]
    labels = [
        mlfFile = "/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData/glob_0000.mlf"
        labelMappingFile = "/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData/state.list"
        labelDim = 132
        labelType = "category"
    ]
]
replaceCriterionNode = [
    action = "edit"
    currModel = "/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/models/cntkSpeech"
    newModel  = "/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/models/cntkSpeech.sequence.0"
    editPath  = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/replace_ce_with_sequence_criterion.mel"
]
sequenceTrain = [
    action = "train"
    modelPath = "/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/models/cntkSpeech.sequence"
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/nonexistentfile.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 10
        learningRatesPerSample = 0.000002
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 3
        hsmoothingWeight = 0.95
        frameDropThresh = 1e-10
        numMBsToShowResult = 10
        gradientClippingWithTruncation = true
        clippingThresholdPerSample = 1.0
    ]
    reader = [
        readerType = "HTKMLFReader"
        readMethod = "blockRandomize"
        frameMode = false
        nbruttsineachrecurrentiter = 2
        miniBatchMode = "partial"
        randomize = "auto"
        verbosity = 0
        features = [
            dim = 363
            type = "real"
            scpFile = "/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData/glob_0000.scp"
        ]
        labels = [
            mlfFile = "/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData/glob_0000.mlf"
            labelMappingFile = "/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData/state.list"
            labelDim = 132
            labelType = "category"
        ]
        hmms = [
            phoneFile  = "/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData/model.overalltying"
            transpFile = "/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData/model.transprob"
        ]
        lattices = [
            denlatTocFile = "/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData/*.lats.toc"
        ]
    ]
]
currentDirectory=/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData
RunDir=/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu
DataDir=/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData
ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining
OutputDir=/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu
DeviceId=0
timestamping=true


Configuration After Processing and Variable Resolution:

configparameters: cntk_sequence.cntk:addLayer2=[    
    action = "edit"
    currLayer = 1
    newLayer = 2
    currModel = "/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/models/Pre1/cntkSpeech"
    newModel  = "/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/models/Pre2/cntkSpeech.0"
    editPath  = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/add_layer.mel"
]

configparameters: cntk_sequence.cntk:AddLayer3=[    
    action = "edit"
    currLayer = 2
    newLayer = 3
    currModel = "/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/models/Pre2/cntkSpeech"
    newModel  = "/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/models/cntkSpeech.0"
    editPath  = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/add_layer.mel"
]

configparameters: cntk_sequence.cntk:command=dptPre1:addLayer2:dptPre2:addLayer3:speechTrain:replaceCriterionNode:sequenceTrain
configparameters: cntk_sequence.cntk:ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining
configparameters: cntk_sequence.cntk:currentDirectory=/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData
configparameters: cntk_sequence.cntk:DataDir=/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData
configparameters: cntk_sequence.cntk:deviceId=0
configparameters: cntk_sequence.cntk:dptPre1=[
    action = "train"
    modelPath = "/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/models/Pre1/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/dnn_1layer.txt"
    ]
]

configparameters: cntk_sequence.cntk:dptPre2=[
    action = "train"
    modelPath = "/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/models/Pre2/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/dnn_1layer.txt"
    ]
]

configparameters: cntk_sequence.cntk:globalInvStdPath=GlobalStats/var.363
configparameters: cntk_sequence.cntk:globalMeanPath=GlobalStats/mean.363
configparameters: cntk_sequence.cntk:globalPriorPath=GlobalStats/prior.132
configparameters: cntk_sequence.cntk:ndlMacros=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/macros.txt
configparameters: cntk_sequence.cntk:OutputDir=/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu
configparameters: cntk_sequence.cntk:precision=float
configparameters: cntk_sequence.cntk:reader=[
    readerType = "HTKMLFReader"
    readMethod = "blockRandomize"
    miniBatchMode = "partial"
    randomize = "auto"
    verbosity = 0
    features = [
        dim = 363
        type = "real"
        scpFile = "/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData/glob_0000.scp"
    ]
    labels = [
        mlfFile = "/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData/glob_0000.mlf"
        labelMappingFile = "/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData/state.list"
        labelDim = 132
        labelType = "category"
    ]
]

configparameters: cntk_sequence.cntk:replaceCriterionNode=[
    action = "edit"
    currModel = "/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/models/cntkSpeech"
    newModel  = "/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/models/cntkSpeech.sequence.0"
    editPath  = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/replace_ce_with_sequence_criterion.mel"
]

configparameters: cntk_sequence.cntk:RunDir=/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu
configparameters: cntk_sequence.cntk:sequenceTrain=[
    action = "train"
    modelPath = "/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/models/cntkSpeech.sequence"
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/nonexistentfile.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 10
        learningRatesPerSample = 0.000002
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 3
        hsmoothingWeight = 0.95
        frameDropThresh = 1e-10
        numMBsToShowResult = 10
        gradientClippingWithTruncation = true
        clippingThresholdPerSample = 1.0
    ]
    reader = [
        readerType = "HTKMLFReader"
        readMethod = "blockRandomize"
        frameMode = false
        nbruttsineachrecurrentiter = 2
        miniBatchMode = "partial"
        randomize = "auto"
        verbosity = 0
        features = [
            dim = 363
            type = "real"
            scpFile = "/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData/glob_0000.scp"
        ]
        labels = [
            mlfFile = "/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData/glob_0000.mlf"
            labelMappingFile = "/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData/state.list"
            labelDim = 132
            labelType = "category"
        ]
        hmms = [
            phoneFile  = "/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData/model.overalltying"
            transpFile = "/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData/model.transprob"
        ]
        lattices = [
            denlatTocFile = "/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData/*.lats.toc"
        ]
    ]
]

configparameters: cntk_sequence.cntk:SGD=[
    epochSize = 81920
    minibatchSize = 256
    learningRatesPerMB = 0.8
    numMBsToShowResult = 10
    momentumPerMB = 0.9
    dropoutRate = 0.0
    maxEpochs = 2
]

configparameters: cntk_sequence.cntk:speechTrain=[
    action = "train"
    modelPath = "/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/models/cntkSpeech"
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/dnn.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 256:512
        learningRatesPerMB = 0.8:1.6
        numMBsToShowResult = 10
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 4
        gradUpdateType = "none"
        normWithAveMultiplier = true
        clippingThresholdPerSample = 1#INF
    ]
]

configparameters: cntk_sequence.cntk:timestamping=true
configparameters: cntk_sequence.cntk:traceLevel=1
configparameters: cntk_sequence.cntk:truncated=false
01/08/2018 04:59:29: Commands: dptPre1 addLayer2 dptPre2 addLayer3 speechTrain replaceCriterionNode sequenceTrain
01/08/2018 04:59:29: precision = "float"

01/08/2018 04:59:29: ##############################################################################
01/08/2018 04:59:29: #                                                                            #
01/08/2018 04:59:29: # dptPre1 command (train action)                                             #
01/08/2018 04:59:29: #                                                                            #
01/08/2018 04:59:29: ##############################################################################

01/08/2018 04:59:29: 
Creating virgin network.
NDLBuilder Using GPU 0
SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4
reading script file /tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData/glob_0000.scp ... 948 entries
total 132 state names in state list /tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData/state.list
htkmlfreader: reading MLF file /tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
01/08/2018 04:59:30: 
Model has 19 nodes. Using GPU 0.

01/08/2018 04:59:30: Training criterion:   ce = CrossEntropyWithSoftmax
01/08/2018 04:59:30: Evaluation criterion: err = ClassificationError


Allocating matrices for forward and/or backward propagation.

Gradient Memory Aliasing: 2 are aliased.
	OL.t (gradient) reuses OL.z (gradient)

Memory Sharing: Out of 29 matrices, 12 are shared as 3, and 17 are not shared.

Here are the ones that share memory:
	{ HL1.t : [512 x *]
	  HL1.t : [512 x *] (gradient)
	  HL1.y : [512 x 1 x *] (gradient)
	  OL.z : [132 x 1 x *] }
	{ HL1.W : [512 x 363] (gradient)
	  HL1.z : [512 x 1 x *]
	  HL1.z : [512 x 1 x *] (gradient)
	  OL.t : [132 x 1 x *]
	  OL.t : [132 x 1 x *] (gradient)
	  OL.z : [132 x 1 x *] (gradient) }
	{ HL1.b : [512 x 1] (gradient)
	  HL1.y : [512 x 1 x *] }

Here are the ones that don't share memory:
	{scaledLogLikelihood : [132 x 1 x *]}
	{ce : [1] (gradient)}
	{OL.W : [132 x 512] (gradient)}
	{OL.b : [132 x 1] (gradient)}
	{logPrior : [132 x 1]}
	{ce : [1]}
	{featNorm : [363 x *]}
	{err : [1]}
	{globalInvStd : [363 x 1]}
	{globalPrior : [132 x 1]}
	{HL1.W : [512 x 363]}
	{HL1.b : [512 x 1]}
	{OL.W : [132 x 512]}
	{OL.b : [132 x 1]}
	{globalMean : [363 x 1]}
	{labels : [132 x *]}
	{features : [363 x *]}


01/08/2018 04:59:30: Training 254084 parameters in 4 out of 4 parameter tensors and 10 nodes with gradient:

01/08/2018 04:59:30: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
01/08/2018 04:59:30: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
01/08/2018 04:59:30: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
01/08/2018 04:59:30: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

01/08/2018 04:59:30: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

01/08/2018 04:59:30: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

01/08/2018 04:59:30: Starting minibatch loop.
01/08/2018 04:59:31:  Epoch[ 1 of 2]-Minibatch[   1-  10, 3.12%]: ce = 3.74183846 * 2560; err = 0.80195313 * 2560; time = 0.2093s; samplesPerSecond = 12229.6
01/08/2018 04:59:31:  Epoch[ 1 of 2]-Minibatch[  11-  20, 6.25%]: ce = 2.91124763 * 2560; err = 0.70898438 * 2560; time = 0.0518s; samplesPerSecond = 49421.8
01/08/2018 04:59:31:  Epoch[ 1 of 2]-Minibatch[  21-  30, 9.38%]: ce = 2.58015900 * 2560; err = 0.66640625 * 2560; time = 0.0517s; samplesPerSecond = 49488.9
01/08/2018 04:59:31:  Epoch[ 1 of 2]-Minibatch[  31-  40, 12.50%]: ce = 2.27427139 * 2560; err = 0.58750000 * 2560; time = 0.0551s; samplesPerSecond = 46444.5
01/08/2018 04:59:31:  Epoch[ 1 of 2]-Minibatch[  41-  50, 15.62%]: ce = 2.05503540 * 2560; err = 0.56093750 * 2560; time = 0.0634s; samplesPerSecond = 40402.8
01/08/2018 04:59:31:  Epoch[ 1 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.91055145 * 2560; err = 0.52812500 * 2560; time = 0.0504s; samplesPerSecond = 50777.0
01/08/2018 04:59:31:  Epoch[ 1 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.81562805 * 2560; err = 0.51171875 * 2560; time = 0.0484s; samplesPerSecond = 52875.1
01/08/2018 04:59:31:  Epoch[ 1 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.68803253 * 2560; err = 0.48476562 * 2560; time = 0.0476s; samplesPerSecond = 53810.9
01/08/2018 04:59:31:  Epoch[ 1 of 2]-Minibatch[  81-  90, 28.12%]: ce = 1.57382050 * 2560; err = 0.45429687 * 2560; time = 0.0479s; samplesPerSecond = 53483.3
01/08/2018 04:59:31:  Epoch[ 1 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.62090302 * 2560; err = 0.47304687 * 2560; time = 0.0595s; samplesPerSecond = 43042.9
01/08/2018 04:59:31:  Epoch[ 1 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.59272614 * 2560; err = 0.47500000 * 2560; time = 0.0663s; samplesPerSecond = 38583.6
01/08/2018 04:59:31:  Epoch[ 1 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.51520386 * 2560; err = 0.44531250 * 2560; time = 0.0503s; samplesPerSecond = 50914.3
01/08/2018 04:59:31:  Epoch[ 1 of 2]-Minibatch[ 121- 130, 40.62%]: ce = 1.49181976 * 2560; err = 0.45039062 * 2560; time = 0.0493s; samplesPerSecond = 51937.3
01/08/2018 04:59:31:  Epoch[ 1 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.53703613 * 2560; err = 0.44804688 * 2560; time = 0.0501s; samplesPerSecond = 51071.6
01/08/2018 04:59:31:  Epoch[ 1 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.43095398 * 2560; err = 0.41640625 * 2560; time = 0.0495s; samplesPerSecond = 51737.7
01/08/2018 04:59:31:  Epoch[ 1 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.41503601 * 2560; err = 0.40078125 * 2560; time = 0.0494s; samplesPerSecond = 51873.0
01/08/2018 04:59:31:  Epoch[ 1 of 2]-Minibatch[ 161- 170, 53.12%]: ce = 1.38912964 * 2560; err = 0.41132812 * 2560; time = 0.0496s; samplesPerSecond = 51634.8
01/08/2018 04:59:31:  Epoch[ 1 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.41208496 * 2560; err = 0.42226562 * 2560; time = 0.0491s; samplesPerSecond = 52170.8
01/08/2018 04:59:31:  Epoch[ 1 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.39966125 * 2560; err = 0.40664062 * 2560; time = 0.0491s; samplesPerSecond = 52113.0
01/08/2018 04:59:32:  Epoch[ 1 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.42728271 * 2560; err = 0.42617187 * 2560; time = 0.0491s; samplesPerSecond = 52169.8
01/08/2018 04:59:32:  Epoch[ 1 of 2]-Minibatch[ 201- 210, 65.62%]: ce = 1.41336060 * 2560; err = 0.42304687 * 2560; time = 0.0491s; samplesPerSecond = 52128.1
01/08/2018 04:59:32:  Epoch[ 1 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.33200073 * 2560; err = 0.39960937 * 2560; time = 0.0517s; samplesPerSecond = 49563.5
01/08/2018 04:59:32:  Epoch[ 1 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.28576965 * 2560; err = 0.38671875 * 2560; time = 0.0854s; samplesPerSecond = 29974.4
01/08/2018 04:59:32:  Epoch[ 1 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.34133301 * 2560; err = 0.40937500 * 2560; time = 0.0540s; samplesPerSecond = 47389.2
01/08/2018 04:59:32:  Epoch[ 1 of 2]-Minibatch[ 241- 250, 78.12%]: ce = 1.32666321 * 2560; err = 0.39609375 * 2560; time = 0.0568s; samplesPerSecond = 45066.4
01/08/2018 04:59:32:  Epoch[ 1 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.21424866 * 2560; err = 0.37226562 * 2560; time = 0.0656s; samplesPerSecond = 39024.8
01/08/2018 04:59:32:  Epoch[ 1 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.23750610 * 2560; err = 0.37382813 * 2560; time = 0.0509s; samplesPerSecond = 50262.4
01/08/2018 04:59:32:  Epoch[ 1 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.29965820 * 2560; err = 0.39062500 * 2560; time = 0.0497s; samplesPerSecond = 51548.2
01/08/2018 04:59:32:  Epoch[ 1 of 2]-Minibatch[ 281- 290, 90.62%]: ce = 1.21221924 * 2560; err = 0.37382813 * 2560; time = 0.0495s; samplesPerSecond = 51727.8
01/08/2018 04:59:32:  Epoch[ 1 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.20538635 * 2560; err = 0.36757812 * 2560; time = 0.0493s; samplesPerSecond = 51893.5
01/08/2018 04:59:32:  Epoch[ 1 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.23562927 * 2560; err = 0.37187500 * 2560; time = 0.0500s; samplesPerSecond = 51205.9
01/08/2018 04:59:32:  Epoch[ 1 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.25470886 * 2560; err = 0.37812500 * 2560; time = 0.0448s; samplesPerSecond = 57176.6
01/08/2018 04:59:32: Finished Epoch[ 1 of 2]: [Training] ce = 1.62940331 * 81920; err = 0.46009521 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=2.60737s
01/08/2018 04:59:32: SGD: Saving checkpoint model '/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/models/Pre1/cntkSpeech.1'

01/08/2018 04:59:32: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

01/08/2018 04:59:32: Starting minibatch loop.
01/08/2018 04:59:32:  Epoch[ 2 of 2]-Minibatch[   1-  10, 3.12%]: ce = 1.23162079 * 2560; err = 0.38125000 * 2560; time = 0.0508s; samplesPerSecond = 50420.7
01/08/2018 04:59:32:  Epoch[ 2 of 2]-Minibatch[  11-  20, 6.25%]: ce = 1.20301991 * 2560; err = 0.37226562 * 2560; time = 0.0494s; samplesPerSecond = 51822.0
01/08/2018 04:59:32:  Epoch[ 2 of 2]-Minibatch[  21-  30, 9.38%]: ce = 1.28580151 * 2560; err = 0.37851563 * 2560; time = 0.0492s; samplesPerSecond = 52069.7
01/08/2018 04:59:32:  Epoch[ 2 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.23043137 * 2560; err = 0.37460938 * 2560; time = 0.0495s; samplesPerSecond = 51694.0
01/08/2018 04:59:32:  Epoch[ 2 of 2]-Minibatch[  41-  50, 15.62%]: ce = 1.18316193 * 2560; err = 0.35429688 * 2560; time = 0.0490s; samplesPerSecond = 52249.7
01/08/2018 04:59:32:  Epoch[ 2 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.27994614 * 2560; err = 0.37812500 * 2560; time = 0.0492s; samplesPerSecond = 52076.6
01/08/2018 04:59:33:  Epoch[ 2 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.22171936 * 2560; err = 0.37070313 * 2560; time = 0.0495s; samplesPerSecond = 51765.0
01/08/2018 04:59:33:  Epoch[ 2 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.17933273 * 2560; err = 0.36250000 * 2560; time = 0.0496s; samplesPerSecond = 51638.0
01/08/2018 04:59:33:  Epoch[ 2 of 2]-Minibatch[  81-  90, 28.12%]: ce = 1.23844833 * 2560; err = 0.36289063 * 2560; time = 0.0492s; samplesPerSecond = 52034.3
01/08/2018 04:59:33:  Epoch[ 2 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.18221588 * 2560; err = 0.37460938 * 2560; time = 0.0496s; samplesPerSecond = 51573.6
01/08/2018 04:59:33:  Epoch[ 2 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.19557495 * 2560; err = 0.36093750 * 2560; time = 0.0544s; samplesPerSecond = 47015.6
01/08/2018 04:59:33:  Epoch[ 2 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.18080750 * 2560; err = 0.35078125 * 2560; time = 0.0492s; samplesPerSecond = 51991.9
01/08/2018 04:59:33:  Epoch[ 2 of 2]-Minibatch[ 121- 130, 40.62%]: ce = 1.16538544 * 2560; err = 0.35820313 * 2560; time = 0.0490s; samplesPerSecond = 52228.7
01/08/2018 04:59:33:  Epoch[ 2 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.13251953 * 2560; err = 0.35039063 * 2560; time = 0.0497s; samplesPerSecond = 51458.4
01/08/2018 04:59:33:  Epoch[ 2 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.09806366 * 2560; err = 0.32539062 * 2560; time = 0.0493s; samplesPerSecond = 51899.3
01/08/2018 04:59:33:  Epoch[ 2 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.10407715 * 2560; err = 0.33984375 * 2560; time = 0.0492s; samplesPerSecond = 51988.7
01/08/2018 04:59:33:  Epoch[ 2 of 2]-Minibatch[ 161- 170, 53.12%]: ce = 1.20419312 * 2560; err = 0.36054687 * 2560; time = 0.0495s; samplesPerSecond = 51747.2
01/08/2018 04:59:33:  Epoch[ 2 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.17373505 * 2560; err = 0.35781250 * 2560; time = 0.0580s; samplesPerSecond = 44124.0
01/08/2018 04:59:33:  Epoch[ 2 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.12243347 * 2560; err = 0.34609375 * 2560; time = 0.0498s; samplesPerSecond = 51372.5
01/08/2018 04:59:33:  Epoch[ 2 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.12005615 * 2560; err = 0.35625000 * 2560; time = 0.0499s; samplesPerSecond = 51281.4
01/08/2018 04:59:33:  Epoch[ 2 of 2]-Minibatch[ 201- 210, 65.62%]: ce = 1.10305176 * 2560; err = 0.33046875 * 2560; time = 0.0500s; samplesPerSecond = 51236.1
01/08/2018 04:59:33:  Epoch[ 2 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.13120422 * 2560; err = 0.34257813 * 2560; time = 0.0500s; samplesPerSecond = 51230.9
01/08/2018 04:59:33:  Epoch[ 2 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.14404602 * 2560; err = 0.35390625 * 2560; time = 0.0496s; samplesPerSecond = 51605.8
01/08/2018 04:59:33:  Epoch[ 2 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.28562622 * 2560; err = 0.39414063 * 2560; time = 0.0496s; samplesPerSecond = 51604.0
01/08/2018 04:59:33:  Epoch[ 2 of 2]-Minibatch[ 241- 250, 78.12%]: ce = 1.17830811 * 2560; err = 0.35585937 * 2560; time = 0.0498s; samplesPerSecond = 51415.2
01/08/2018 04:59:34:  Epoch[ 2 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.12961731 * 2560; err = 0.35820313 * 2560; time = 0.0524s; samplesPerSecond = 48818.3
01/08/2018 04:59:34:  Epoch[ 2 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.13842163 * 2560; err = 0.34843750 * 2560; time = 0.0570s; samplesPerSecond = 44888.5
01/08/2018 04:59:34:  Epoch[ 2 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.14543152 * 2560; err = 0.34648438 * 2560; time = 0.0546s; samplesPerSecond = 46899.1
01/08/2018 04:59:34:  Epoch[ 2 of 2]-Minibatch[ 281- 290, 90.62%]: ce = 1.06640625 * 2560; err = 0.33203125 * 2560; time = 0.0649s; samplesPerSecond = 39471.0
01/08/2018 04:59:34:  Epoch[ 2 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.10130005 * 2560; err = 0.33593750 * 2560; time = 0.0610s; samplesPerSecond = 41944.9
01/08/2018 04:59:34:  Epoch[ 2 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.08510742 * 2560; err = 0.33750000 * 2560; time = 0.0591s; samplesPerSecond = 43343.9
01/08/2018 04:59:34:  Epoch[ 2 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.06571045 * 2560; err = 0.33515625 * 2560; time = 0.0515s; samplesPerSecond = 49676.5
01/08/2018 04:59:34: Finished Epoch[ 2 of 2]: [Training] ce = 1.16583672 * 81920; err = 0.35583496 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=1.66233s
01/08/2018 04:59:34: SGD: Saving checkpoint model '/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/models/Pre1/cntkSpeech'

01/08/2018 04:59:34: Action "train" complete.


01/08/2018 04:59:34: ##############################################################################
01/08/2018 04:59:34: #                                                                            #
01/08/2018 04:59:34: # addLayer2 command (edit action)                                            #
01/08/2018 04:59:34: #                                                                            #
01/08/2018 04:59:34: ##############################################################################


01/08/2018 04:59:34: Action "edit" complete.


01/08/2018 04:59:34: ##############################################################################
01/08/2018 04:59:34: #                                                                            #
01/08/2018 04:59:34: # dptPre2 command (train action)                                             #
01/08/2018 04:59:34: #                                                                            #
01/08/2018 04:59:34: ##############################################################################

01/08/2018 04:59:34: 
Starting from checkpoint. Loading network from '/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/models/Pre2/cntkSpeech.0'.
NDLBuilder Using GPU 0
reading script file /tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData/glob_0000.scp ... 948 entries
total 132 state names in state list /tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData/state.list
htkmlfreader: reading MLF file /tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
01/08/2018 04:59:34: 
Model has 24 nodes. Using GPU 0.

01/08/2018 04:59:34: Training criterion:   ce = CrossEntropyWithSoftmax
01/08/2018 04:59:34: Evaluation criterion: err = ClassificationError

01/08/2018 04:59:34: Training 516740 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:

01/08/2018 04:59:34: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
01/08/2018 04:59:34: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
01/08/2018 04:59:34: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
01/08/2018 04:59:34: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
01/08/2018 04:59:34: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
01/08/2018 04:59:34: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

01/08/2018 04:59:34: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

01/08/2018 04:59:34: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

01/08/2018 04:59:35: Starting minibatch loop.
01/08/2018 04:59:35:  Epoch[ 1 of 2]-Minibatch[   1-  10, 3.12%]: ce = 4.61674881 * 2560; err = 0.80742187 * 2560; time = 0.0663s; samplesPerSecond = 38612.6
01/08/2018 04:59:35:  Epoch[ 1 of 2]-Minibatch[  11-  20, 6.25%]: ce = 2.86666870 * 2560; err = 0.70507812 * 2560; time = 0.0635s; samplesPerSecond = 40308.5
01/08/2018 04:59:35:  Epoch[ 1 of 2]-Minibatch[  21-  30, 9.38%]: ce = 2.29427795 * 2560; err = 0.59960938 * 2560; time = 0.0630s; samplesPerSecond = 40642.3
01/08/2018 04:59:35:  Epoch[ 1 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.96351089 * 2560; err = 0.52851563 * 2560; time = 0.0634s; samplesPerSecond = 40398.3
01/08/2018 04:59:35:  Epoch[ 1 of 2]-Minibatch[  41-  50, 15.62%]: ce = 1.74446564 * 2560; err = 0.48007813 * 2560; time = 0.0665s; samplesPerSecond = 38517.8
01/08/2018 04:59:35:  Epoch[ 1 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.62170563 * 2560; err = 0.45546875 * 2560; time = 0.0658s; samplesPerSecond = 38879.5
01/08/2018 04:59:35:  Epoch[ 1 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.57501984 * 2560; err = 0.45546875 * 2560; time = 0.0624s; samplesPerSecond = 40997.1
01/08/2018 04:59:35:  Epoch[ 1 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.47702789 * 2560; err = 0.42773438 * 2560; time = 0.0635s; samplesPerSecond = 40335.7
01/08/2018 04:59:35:  Epoch[ 1 of 2]-Minibatch[  81-  90, 28.12%]: ce = 1.38880768 * 2560; err = 0.40156250 * 2560; time = 0.0617s; samplesPerSecond = 41472.5
01/08/2018 04:59:35:  Epoch[ 1 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.42063293 * 2560; err = 0.42773438 * 2560; time = 0.0617s; samplesPerSecond = 41509.8
01/08/2018 04:59:36:  Epoch[ 1 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.41058807 * 2560; err = 0.43789062 * 2560; time = 0.0637s; samplesPerSecond = 40216.7
01/08/2018 04:59:36:  Epoch[ 1 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.38001099 * 2560; err = 0.41445312 * 2560; time = 0.0618s; samplesPerSecond = 41445.6
01/08/2018 04:59:36:  Epoch[ 1 of 2]-Minibatch[ 121- 130, 40.62%]: ce = 1.34645538 * 2560; err = 0.41250000 * 2560; time = 0.0631s; samplesPerSecond = 40557.8
01/08/2018 04:59:36:  Epoch[ 1 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.38398743 * 2560; err = 0.40195313 * 2560; time = 0.0618s; samplesPerSecond = 41432.1
01/08/2018 04:59:36:  Epoch[ 1 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.32409363 * 2560; err = 0.38984375 * 2560; time = 0.0617s; samplesPerSecond = 41469.4
01/08/2018 04:59:36:  Epoch[ 1 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.31575928 * 2560; err = 0.39414063 * 2560; time = 0.0641s; samplesPerSecond = 39963.2
01/08/2018 04:59:36:  Epoch[ 1 of 2]-Minibatch[ 161- 170, 53.12%]: ce = 1.25869446 * 2560; err = 0.37148437 * 2560; time = 0.0617s; samplesPerSecond = 41467.1
01/08/2018 04:59:36:  Epoch[ 1 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.27994385 * 2560; err = 0.38398437 * 2560; time = 0.0617s; samplesPerSecond = 41507.6
01/08/2018 04:59:36:  Epoch[ 1 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.29792175 * 2560; err = 0.39335938 * 2560; time = 0.0619s; samplesPerSecond = 41375.0
01/08/2018 04:59:36:  Epoch[ 1 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.28697815 * 2560; err = 0.39843750 * 2560; time = 0.0624s; samplesPerSecond = 41011.2
01/08/2018 04:59:36:  Epoch[ 1 of 2]-Minibatch[ 201- 210, 65.62%]: ce = 1.26717834 * 2560; err = 0.38593750 * 2560; time = 0.0637s; samplesPerSecond = 40178.7
01/08/2018 04:59:36:  Epoch[ 1 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.21615295 * 2560; err = 0.36718750 * 2560; time = 0.0619s; samplesPerSecond = 41362.3
01/08/2018 04:59:36:  Epoch[ 1 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.21445923 * 2560; err = 0.37031250 * 2560; time = 0.0617s; samplesPerSecond = 41480.7
01/08/2018 04:59:36:  Epoch[ 1 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.25004578 * 2560; err = 0.38085938 * 2560; time = 0.0640s; samplesPerSecond = 40006.9
01/08/2018 04:59:36:  Epoch[ 1 of 2]-Minibatch[ 241- 250, 78.12%]: ce = 1.22538452 * 2560; err = 0.37656250 * 2560; time = 0.0615s; samplesPerSecond = 41655.1
01/08/2018 04:59:36:  Epoch[ 1 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.15360413 * 2560; err = 0.34843750 * 2560; time = 0.0615s; samplesPerSecond = 41624.1
01/08/2018 04:59:37:  Epoch[ 1 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.16656189 * 2560; err = 0.35312500 * 2560; time = 0.0635s; samplesPerSecond = 40303.2
01/08/2018 04:59:37:  Epoch[ 1 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.22569275 * 2560; err = 0.36640625 * 2560; time = 0.0619s; samplesPerSecond = 41374.5
01/08/2018 04:59:37:  Epoch[ 1 of 2]-Minibatch[ 281- 290, 90.62%]: ce = 1.16463623 * 2560; err = 0.36054687 * 2560; time = 0.0618s; samplesPerSecond = 41433.5
01/08/2018 04:59:37:  Epoch[ 1 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.16964111 * 2560; err = 0.35351562 * 2560; time = 0.0624s; samplesPerSecond = 40994.6
01/08/2018 04:59:37:  Epoch[ 1 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.16557617 * 2560; err = 0.35351562 * 2560; time = 0.0744s; samplesPerSecond = 34399.6
01/08/2018 04:59:37:  Epoch[ 1 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.17247925 * 2560; err = 0.35156250 * 2560; time = 0.0580s; samplesPerSecond = 44111.3
01/08/2018 04:59:37: Finished Epoch[ 1 of 2]: [Training] ce = 1.52014723 * 81920; err = 0.42670898 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=2.77624s
01/08/2018 04:59:37: SGD: Saving checkpoint model '/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/models/Pre2/cntkSpeech.1'

01/08/2018 04:59:37: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

01/08/2018 04:59:37: Starting minibatch loop.
01/08/2018 04:59:37:  Epoch[ 2 of 2]-Minibatch[   1-  10, 3.12%]: ce = 1.14981880 * 2560; err = 0.35156250 * 2560; time = 0.0633s; samplesPerSecond = 40456.2
01/08/2018 04:59:37:  Epoch[ 2 of 2]-Minibatch[  11-  20, 6.25%]: ce = 1.17322617 * 2560; err = 0.36015625 * 2560; time = 0.0615s; samplesPerSecond = 41613.3
01/08/2018 04:59:37:  Epoch[ 2 of 2]-Minibatch[  21-  30, 9.38%]: ce = 1.22602234 * 2560; err = 0.37460938 * 2560; time = 0.0616s; samplesPerSecond = 41560.5
01/08/2018 04:59:37:  Epoch[ 2 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.18246918 * 2560; err = 0.36015625 * 2560; time = 0.0633s; samplesPerSecond = 40429.9
01/08/2018 04:59:37:  Epoch[ 2 of 2]-Minibatch[  41-  50, 15.62%]: ce = 1.13529053 * 2560; err = 0.34453125 * 2560; time = 0.0613s; samplesPerSecond = 41735.5
01/08/2018 04:59:37:  Epoch[ 2 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.21815300 * 2560; err = 0.36640625 * 2560; time = 0.0616s; samplesPerSecond = 41589.5
01/08/2018 04:59:37:  Epoch[ 2 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.14050827 * 2560; err = 0.34140625 * 2560; time = 0.0632s; samplesPerSecond = 40512.4
01/08/2018 04:59:37:  Epoch[ 2 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.12378693 * 2560; err = 0.35312500 * 2560; time = 0.0616s; samplesPerSecond = 41542.1
01/08/2018 04:59:37:  Epoch[ 2 of 2]-Minibatch[  81-  90, 28.12%]: ce = 1.14636002 * 2560; err = 0.33906250 * 2560; time = 0.0623s; samplesPerSecond = 41109.4
01/08/2018 04:59:38:  Epoch[ 2 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.12752228 * 2560; err = 0.34843750 * 2560; time = 0.0642s; samplesPerSecond = 39859.2
01/08/2018 04:59:38:  Epoch[ 2 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.14752197 * 2560; err = 0.34414062 * 2560; time = 0.0654s; samplesPerSecond = 39172.7
01/08/2018 04:59:38:  Epoch[ 2 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.12730484 * 2560; err = 0.34140625 * 2560; time = 0.0653s; samplesPerSecond = 39176.4
01/08/2018 04:59:38:  Epoch[ 2 of 2]-Minibatch[ 121- 130, 40.62%]: ce = 1.11186981 * 2560; err = 0.34179688 * 2560; time = 0.0668s; samplesPerSecond = 38316.4
01/08/2018 04:59:38:  Epoch[ 2 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.07041931 * 2560; err = 0.32617188 * 2560; time = 0.0681s; samplesPerSecond = 37606.6
01/08/2018 04:59:38:  Epoch[ 2 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.05150299 * 2560; err = 0.31250000 * 2560; time = 0.0627s; samplesPerSecond = 40803.3
01/08/2018 04:59:38:  Epoch[ 2 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.06874542 * 2560; err = 0.33007812 * 2560; time = 0.0621s; samplesPerSecond = 41192.3
01/08/2018 04:59:38:  Epoch[ 2 of 2]-Minibatch[ 161- 170, 53.12%]: ce = 1.14110870 * 2560; err = 0.34687500 * 2560; time = 0.0629s; samplesPerSecond = 40681.0
01/08/2018 04:59:38:  Epoch[ 2 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.13898926 * 2560; err = 0.36132812 * 2560; time = 0.0623s; samplesPerSecond = 41067.0
01/08/2018 04:59:38:  Epoch[ 2 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.08064728 * 2560; err = 0.33437500 * 2560; time = 0.0653s; samplesPerSecond = 39207.7
01/08/2018 04:59:38:  Epoch[ 2 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.07247162 * 2560; err = 0.33984375 * 2560; time = 0.0619s; samplesPerSecond = 41349.9
01/08/2018 04:59:38:  Epoch[ 2 of 2]-Minibatch[ 201- 210, 65.62%]: ce = 1.06161499 * 2560; err = 0.32539062 * 2560; time = 0.0657s; samplesPerSecond = 38958.0
01/08/2018 04:59:38:  Epoch[ 2 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.09126740 * 2560; err = 0.33242187 * 2560; time = 0.0638s; samplesPerSecond = 40116.8
01/08/2018 04:59:38:  Epoch[ 2 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.11266785 * 2560; err = 0.34492187 * 2560; time = 0.0622s; samplesPerSecond = 41150.3
01/08/2018 04:59:38:  Epoch[ 2 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.12638855 * 2560; err = 0.35273437 * 2560; time = 0.0627s; samplesPerSecond = 40824.2
01/08/2018 04:59:38:  Epoch[ 2 of 2]-Minibatch[ 241- 250, 78.12%]: ce = 1.08986816 * 2560; err = 0.33984375 * 2560; time = 0.0693s; samplesPerSecond = 36953.9
01/08/2018 04:59:39:  Epoch[ 2 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.06911316 * 2560; err = 0.33398438 * 2560; time = 0.0626s; samplesPerSecond = 40886.2
01/08/2018 04:59:39:  Epoch[ 2 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.06766663 * 2560; err = 0.32460937 * 2560; time = 0.0615s; samplesPerSecond = 41642.0
01/08/2018 04:59:39:  Epoch[ 2 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.09992981 * 2560; err = 0.33203125 * 2560; time = 0.0617s; samplesPerSecond = 41458.7
01/08/2018 04:59:39:  Epoch[ 2 of 2]-Minibatch[ 281- 290, 90.62%]: ce = 1.02154846 * 2560; err = 0.32539062 * 2560; time = 0.0656s; samplesPerSecond = 39007.7
01/08/2018 04:59:39:  Epoch[ 2 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.07519226 * 2560; err = 0.33281250 * 2560; time = 0.0617s; samplesPerSecond = 41506.1
01/08/2018 04:59:39:  Epoch[ 2 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.06713867 * 2560; err = 0.32812500 * 2560; time = 0.0618s; samplesPerSecond = 41429.8
01/08/2018 04:59:39:  Epoch[ 2 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.05164185 * 2560; err = 0.32890625 * 2560; time = 0.0586s; samplesPerSecond = 43672.5
01/08/2018 04:59:39: Finished Epoch[ 2 of 2]: [Training] ce = 1.11149302 * 81920; err = 0.34122314 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=2.03376s
01/08/2018 04:59:39: SGD: Saving checkpoint model '/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/models/Pre2/cntkSpeech'

01/08/2018 04:59:39: Action "train" complete.


01/08/2018 04:59:39: ##############################################################################
01/08/2018 04:59:39: #                                                                            #
01/08/2018 04:59:39: # addLayer3 command (edit action)                                            #
01/08/2018 04:59:39: #                                                                            #
01/08/2018 04:59:39: ##############################################################################


01/08/2018 04:59:39: Action "edit" complete.


01/08/2018 04:59:39: ##############################################################################
01/08/2018 04:59:39: #                                                                            #
01/08/2018 04:59:39: # speechTrain command (train action)                                         #
01/08/2018 04:59:39: #                                                                            #
01/08/2018 04:59:39: ##############################################################################

01/08/2018 04:59:39: 
Starting from checkpoint. Loading network from '/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/models/cntkSpeech.0'.
NDLBuilder Using GPU 0
reading script file /tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData/glob_0000.scp ... 948 entries
total 132 state names in state list /tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData/state.list
htkmlfreader: reading MLF file /tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
01/08/2018 04:59:39: 
Model has 29 nodes. Using GPU 0.

01/08/2018 04:59:39: Training criterion:   ce = CrossEntropyWithSoftmax
01/08/2018 04:59:39: Evaluation criterion: err = ClassificationError

01/08/2018 04:59:39: Training 779396 parameters in 8 out of 8 parameter tensors and 20 nodes with gradient:

01/08/2018 04:59:39: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
01/08/2018 04:59:39: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
01/08/2018 04:59:39: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
01/08/2018 04:59:39: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
01/08/2018 04:59:39: 	Node 'HL3.W' (LearnableParameter operation) : [512 x 512]
01/08/2018 04:59:39: 	Node 'HL3.b' (LearnableParameter operation) : [512 x 1]
01/08/2018 04:59:39: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
01/08/2018 04:59:39: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

01/08/2018 04:59:39: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

01/08/2018 04:59:39: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900117  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

01/08/2018 04:59:40: Starting minibatch loop.
01/08/2018 04:59:40:  Epoch[ 1 of 4]-Minibatch[   1-  10, 3.12%]: ce = 3.98869972 * 2560; err = 0.81562500 * 2560; time = 0.0860s; samplesPerSecond = 29756.1
01/08/2018 04:59:40:  Epoch[ 1 of 4]-Minibatch[  11-  20, 6.25%]: ce = 2.65266838 * 2560; err = 0.64531250 * 2560; time = 0.0760s; samplesPerSecond = 33688.1
01/08/2018 04:59:40:  Epoch[ 1 of 4]-Minibatch[  21-  30, 9.38%]: ce = 2.04071579 * 2560; err = 0.54687500 * 2560; time = 0.0736s; samplesPerSecond = 34768.4
01/08/2018 04:59:40:  Epoch[ 1 of 4]-Minibatch[  31-  40, 12.50%]: ce = 1.74825745 * 2560; err = 0.47539063 * 2560; time = 0.0762s; samplesPerSecond = 33577.4
01/08/2018 04:59:40:  Epoch[ 1 of 4]-Minibatch[  41-  50, 15.62%]: ce = 1.57756348 * 2560; err = 0.44921875 * 2560; time = 0.0829s; samplesPerSecond = 30866.7
01/08/2018 04:59:40:  Epoch[ 1 of 4]-Minibatch[  51-  60, 18.75%]: ce = 1.47807083 * 2560; err = 0.41835937 * 2560; time = 0.0703s; samplesPerSecond = 36403.1
01/08/2018 04:59:41:  Epoch[ 1 of 4]-Minibatch[  61-  70, 21.88%]: ce = 1.44050140 * 2560; err = 0.41015625 * 2560; time = 0.0737s; samplesPerSecond = 34720.6
01/08/2018 04:59:41:  Epoch[ 1 of 4]-Minibatch[  71-  80, 25.00%]: ce = 1.36226807 * 2560; err = 0.39726563 * 2560; time = 0.0701s; samplesPerSecond = 36537.5
01/08/2018 04:59:41:  Epoch[ 1 of 4]-Minibatch[  81-  90, 28.12%]: ce = 1.28130646 * 2560; err = 0.37578125 * 2560; time = 0.0783s; samplesPerSecond = 32682.4
01/08/2018 04:59:41:  Epoch[ 1 of 4]-Minibatch[  91- 100, 31.25%]: ce = 1.30515137 * 2560; err = 0.40195313 * 2560; time = 0.0680s; samplesPerSecond = 37621.7
01/08/2018 04:59:41:  Epoch[ 1 of 4]-Minibatch[ 101- 110, 34.38%]: ce = 1.28546295 * 2560; err = 0.38984375 * 2560; time = 0.0673s; samplesPerSecond = 38055.7
01/08/2018 04:59:41:  Epoch[ 1 of 4]-Minibatch[ 111- 120, 37.50%]: ce = 1.27684479 * 2560; err = 0.38281250 * 2560; time = 0.0677s; samplesPerSecond = 37806.7
01/08/2018 04:59:41:  Epoch[ 1 of 4]-Minibatch[ 121- 130, 40.62%]: ce = 1.24204254 * 2560; err = 0.38281250 * 2560; time = 0.0676s; samplesPerSecond = 37892.2
01/08/2018 04:59:41:  Epoch[ 1 of 4]-Minibatch[ 131- 140, 43.75%]: ce = 1.30829010 * 2560; err = 0.38320312 * 2560; time = 0.0785s; samplesPerSecond = 32608.4
01/08/2018 04:59:41:  Epoch[ 1 of 4]-Minibatch[ 141- 150, 46.88%]: ce = 1.24720459 * 2560; err = 0.36367187 * 2560; time = 0.0777s; samplesPerSecond = 32948.2
01/08/2018 04:59:41:  Epoch[ 1 of 4]-Minibatch[ 151- 160, 50.00%]: ce = 1.26371307 * 2560; err = 0.38242188 * 2560; time = 0.0675s; samplesPerSecond = 37923.3
01/08/2018 04:59:41:  Epoch[ 1 of 4]-Minibatch[ 161- 170, 53.12%]: ce = 1.20174866 * 2560; err = 0.36210938 * 2560; time = 0.0669s; samplesPerSecond = 38244.2
01/08/2018 04:59:41:  Epoch[ 1 of 4]-Minibatch[ 171- 180, 56.25%]: ce = 1.20651245 * 2560; err = 0.36718750 * 2560; time = 0.0668s; samplesPerSecond = 38297.1
01/08/2018 04:59:41:  Epoch[ 1 of 4]-Minibatch[ 181- 190, 59.38%]: ce = 1.21452942 * 2560; err = 0.36718750 * 2560; time = 0.0883s; samplesPerSecond = 28978.8
01/08/2018 04:59:41:  Epoch[ 1 of 4]-Minibatch[ 191- 200, 62.50%]: ce = 1.20404053 * 2560; err = 0.37617187 * 2560; time = 0.0661s; samplesPerSecond = 38713.3
01/08/2018 04:59:42:  Epoch[ 1 of 4]-Minibatch[ 201- 210, 65.62%]: ce = 1.20572510 * 2560; err = 0.36875000 * 2560; time = 0.0665s; samplesPerSecond = 38502.6
01/08/2018 04:59:42:  Epoch[ 1 of 4]-Minibatch[ 211- 220, 68.75%]: ce = 1.14164734 * 2560; err = 0.34765625 * 2560; time = 0.0664s; samplesPerSecond = 38536.3
01/08/2018 04:59:42:  Epoch[ 1 of 4]-Minibatch[ 221- 230, 71.88%]: ce = 1.14932861 * 2560; err = 0.34921875 * 2560; time = 0.0686s; samplesPerSecond = 37310.9
01/08/2018 04:59:42:  Epoch[ 1 of 4]-Minibatch[ 231- 240, 75.00%]: ce = 1.18699341 * 2560; err = 0.35117188 * 2560; time = 0.0672s; samplesPerSecond = 38120.2
01/08/2018 04:59:42:  Epoch[ 1 of 4]-Minibatch[ 241- 250, 78.12%]: ce = 1.16585693 * 2560; err = 0.36054687 * 2560; time = 0.0667s; samplesPerSecond = 38408.3
01/08/2018 04:59:42:  Epoch[ 1 of 4]-Minibatch[ 251- 260, 81.25%]: ce = 1.08444214 * 2560; err = 0.33945313 * 2560; time = 0.0688s; samplesPerSecond = 37191.6
01/08/2018 04:59:42:  Epoch[ 1 of 4]-Minibatch[ 261- 270, 84.38%]: ce = 1.11162720 * 2560; err = 0.34023437 * 2560; time = 0.0666s; samplesPerSecond = 38433.0
01/08/2018 04:59:42:  Epoch[ 1 of 4]-Minibatch[ 271- 280, 87.50%]: ce = 1.17780457 * 2560; err = 0.34687500 * 2560; time = 0.0686s; samplesPerSecond = 37344.2
01/08/2018 04:59:42:  Epoch[ 1 of 4]-Minibatch[ 281- 290, 90.62%]: ce = 1.11032715 * 2560; err = 0.34062500 * 2560; time = 0.0661s; samplesPerSecond = 38709.9
01/08/2018 04:59:42:  Epoch[ 1 of 4]-Minibatch[ 291- 300, 93.75%]: ce = 1.13506470 * 2560; err = 0.34648438 * 2560; time = 0.0663s; samplesPerSecond = 38605.3
01/08/2018 04:59:42:  Epoch[ 1 of 4]-Minibatch[ 301- 310, 96.88%]: ce = 1.12134094 * 2560; err = 0.34101562 * 2560; time = 0.0685s; samplesPerSecond = 37360.1
01/08/2018 04:59:42:  Epoch[ 1 of 4]-Minibatch[ 311- 320, 100.00%]: ce = 1.12438660 * 2560; err = 0.34335938 * 2560; time = 0.0618s; samplesPerSecond = 41409.1
01/08/2018 04:59:42: Finished Epoch[ 1 of 4]: [Training] ce = 1.40750427 * 81920; err = 0.40214844 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=3.04949s
01/08/2018 04:59:42: SGD: Saving checkpoint model '/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/models/cntkSpeech.1'

01/08/2018 04:59:42: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

01/08/2018 04:59:42: Starting minibatch loop.
01/08/2018 04:59:42:  Epoch[ 2 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.46610394 * 5120; err = 0.40996094 * 5120; time = 0.1042s; samplesPerSecond = 49116.1
01/08/2018 04:59:43:  Epoch[ 2 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.50110569 * 5120; err = 0.41347656 * 5120; time = 0.1026s; samplesPerSecond = 49888.6
01/08/2018 04:59:43:  Epoch[ 2 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.21108513 * 5120; err = 0.36640625 * 5120; time = 0.1018s; samplesPerSecond = 50301.2
01/08/2018 04:59:43:  Epoch[ 2 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.12810822 * 5120; err = 0.34023437 * 5120; time = 0.1018s; samplesPerSecond = 50311.7
01/08/2018 04:59:43:  Epoch[ 2 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.11897316 * 5120; err = 0.33847656 * 5120; time = 0.1020s; samplesPerSecond = 50206.4
01/08/2018 04:59:43:  Epoch[ 2 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.13299255 * 5120; err = 0.34335938 * 5120; time = 0.1024s; samplesPerSecond = 49996.9
01/08/2018 04:59:43:  Epoch[ 2 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.08451233 * 5120; err = 0.33515625 * 5120; time = 0.1018s; samplesPerSecond = 50279.1
01/08/2018 04:59:43:  Epoch[ 2 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.07491379 * 5120; err = 0.32695313 * 5120; time = 0.1088s; samplesPerSecond = 47062.1
01/08/2018 04:59:43:  Epoch[ 2 of 4]-Minibatch[  81-  90, 56.25%]: ce = 1.14153519 * 5120; err = 0.35410156 * 5120; time = 0.1019s; samplesPerSecond = 50246.8
01/08/2018 04:59:43:  Epoch[ 2 of 4]-Minibatch[  91- 100, 62.50%]: ce = 1.06857758 * 5120; err = 0.33339844 * 5120; time = 0.1022s; samplesPerSecond = 50091.2
01/08/2018 04:59:43:  Epoch[ 2 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.05950546 * 5120; err = 0.33046875 * 5120; time = 0.1016s; samplesPerSecond = 50370.3
01/08/2018 04:59:44:  Epoch[ 2 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.13561249 * 5120; err = 0.35058594 * 5120; time = 0.1022s; samplesPerSecond = 50094.6
01/08/2018 04:59:44:  Epoch[ 2 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.12639160 * 5120; err = 0.35410156 * 5120; time = 0.1019s; samplesPerSecond = 50269.3
01/08/2018 04:59:44:  Epoch[ 2 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 1.10322723 * 5120; err = 0.33828125 * 5120; time = 0.1024s; samplesPerSecond = 49982.4
01/08/2018 04:59:44:  Epoch[ 2 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 1.04754944 * 5120; err = 0.33144531 * 5120; time = 0.1017s; samplesPerSecond = 50334.2
01/08/2018 04:59:44:  Epoch[ 2 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 1.05628357 * 5120; err = 0.32441406 * 5120; time = 0.0927s; samplesPerSecond = 55221.6
01/08/2018 04:59:44: Finished Epoch[ 2 of 4]: [Training] ce = 1.15352983 * 81920; err = 0.34942627 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=1.64759s
01/08/2018 04:59:44: SGD: Saving checkpoint model '/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/models/cntkSpeech.2'

01/08/2018 04:59:44: Starting Epoch 3: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 2: frames [163840..245760] (first utterance at frame 163840), data subset 0 of 1, with 1 datapasses

01/08/2018 04:59:44: Starting minibatch loop.
01/08/2018 04:59:44:  Epoch[ 3 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.11074848 * 5120; err = 0.34375000 * 5120; time = 0.1071s; samplesPerSecond = 47810.7
01/08/2018 04:59:44:  Epoch[ 3 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.10125542 * 5120; err = 0.34550781 * 5120; time = 0.1064s; samplesPerSecond = 48129.1
01/08/2018 04:59:44:  Epoch[ 3 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.08591633 * 5120; err = 0.34277344 * 5120; time = 0.1034s; samplesPerSecond = 49518.6
01/08/2018 04:59:44:  Epoch[ 3 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.10742760 * 5120; err = 0.33554688 * 5120; time = 0.1017s; samplesPerSecond = 50325.3
01/08/2018 04:59:45:  Epoch[ 3 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.12246552 * 5120; err = 0.33886719 * 5120; time = 0.1101s; samplesPerSecond = 46522.4
01/08/2018 04:59:45:  Epoch[ 3 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.08610725 * 5120; err = 0.33730469 * 5120; time = 0.1024s; samplesPerSecond = 50002.5
01/08/2018 04:59:45:  Epoch[ 3 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.08662262 * 5120; err = 0.33417969 * 5120; time = 0.1018s; samplesPerSecond = 50318.6
01/08/2018 04:59:45:  Epoch[ 3 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.06978607 * 5120; err = 0.32246094 * 5120; time = 0.1019s; samplesPerSecond = 50226.5
01/08/2018 04:59:45:  Epoch[ 3 of 4]-Minibatch[  81-  90, 56.25%]: ce = 1.02804794 * 5120; err = 0.31328125 * 5120; time = 0.1021s; samplesPerSecond = 50144.6
01/08/2018 04:59:45:  Epoch[ 3 of 4]-Minibatch[  91- 100, 62.50%]: ce = 1.04875183 * 5120; err = 0.31875000 * 5120; time = 0.1018s; samplesPerSecond = 50274.4
01/08/2018 04:59:45:  Epoch[ 3 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.05174637 * 5120; err = 0.33476563 * 5120; time = 0.1020s; samplesPerSecond = 50217.1
01/08/2018 04:59:45:  Epoch[ 3 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.07829895 * 5120; err = 0.33593750 * 5120; time = 0.1022s; samplesPerSecond = 50099.1
01/08/2018 04:59:45:  Epoch[ 3 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.05014038 * 5120; err = 0.31875000 * 5120; time = 0.1025s; samplesPerSecond = 49970.9
01/08/2018 04:59:46:  Epoch[ 3 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 1.02171173 * 5120; err = 0.32167969 * 5120; time = 0.1089s; samplesPerSecond = 47009.0
01/08/2018 04:59:46:  Epoch[ 3 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 1.04328461 * 5120; err = 0.32851562 * 5120; time = 0.1101s; samplesPerSecond = 46507.7
01/08/2018 04:59:46:  Epoch[ 3 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 1.01844177 * 5120; err = 0.31875000 * 5120; time = 0.1173s; samplesPerSecond = 43658.6
01/08/2018 04:59:46: Finished Epoch[ 3 of 4]: [Training] ce = 1.06942205 * 81920; err = 0.33067627 * 81920; totalSamplesSeen = 245760; learningRatePerSample = 0.003125; epochTime=1.69818s
01/08/2018 04:59:46: SGD: Saving checkpoint model '/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/models/cntkSpeech.3'

01/08/2018 04:59:46: Starting Epoch 4: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 3: frames [245760..327680] (first utterance at frame 245760), data subset 0 of 1, with 1 datapasses

01/08/2018 04:59:46: Starting minibatch loop.
01/08/2018 04:59:46:  Epoch[ 4 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.03536406 * 5120; err = 0.31777344 * 5120; time = 0.1038s; samplesPerSecond = 49348.1
01/08/2018 04:59:46:  Epoch[ 4 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.03895218 * 4926; err = 0.32541616 * 4926; time = 0.3203s; samplesPerSecond = 15378.6
01/08/2018 04:59:46:  Epoch[ 4 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.00940247 * 5120; err = 0.32109375 * 5120; time = 0.1028s; samplesPerSecond = 49804.0
01/08/2018 04:59:46:  Epoch[ 4 of 4]-Minibatch[  31-  40, 25.00%]: ce = 0.99019489 * 5120; err = 0.31230469 * 5120; time = 0.1022s; samplesPerSecond = 50112.2
01/08/2018 04:59:47:  Epoch[ 4 of 4]-Minibatch[  41-  50, 31.25%]: ce = 0.99245567 * 5120; err = 0.31425781 * 5120; time = 0.1024s; samplesPerSecond = 50023.7
01/08/2018 04:59:47:  Epoch[ 4 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.00989609 * 5120; err = 0.32246094 * 5120; time = 0.1072s; samplesPerSecond = 47781.9
01/08/2018 04:59:47:  Epoch[ 4 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.01605911 * 5120; err = 0.31718750 * 5120; time = 0.1039s; samplesPerSecond = 49280.2
01/08/2018 04:59:47:  Epoch[ 4 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.00204391 * 5120; err = 0.31464844 * 5120; time = 0.1087s; samplesPerSecond = 47087.4
01/08/2018 04:59:47:  Epoch[ 4 of 4]-Minibatch[  81-  90, 56.25%]: ce = 0.99435730 * 5120; err = 0.30527344 * 5120; time = 0.1045s; samplesPerSecond = 48996.4
01/08/2018 04:59:47:  Epoch[ 4 of 4]-Minibatch[  91- 100, 62.50%]: ce = 0.99423981 * 5120; err = 0.30605469 * 5120; time = 0.1021s; samplesPerSecond = 50152.4
01/08/2018 04:59:47:  Epoch[ 4 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.01819534 * 5120; err = 0.31035156 * 5120; time = 0.1028s; samplesPerSecond = 49790.3
01/08/2018 04:59:47:  Epoch[ 4 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.04231644 * 5120; err = 0.32695313 * 5120; time = 0.1015s; samplesPerSecond = 50433.0
01/08/2018 04:59:47:  Epoch[ 4 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 0.98021393 * 5120; err = 0.30078125 * 5120; time = 0.1024s; samplesPerSecond = 49983.2
01/08/2018 04:59:47:  Epoch[ 4 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 0.97062073 * 5120; err = 0.30136719 * 5120; time = 0.1013s; samplesPerSecond = 50555.7
01/08/2018 04:59:48:  Epoch[ 4 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 0.98007813 * 5120; err = 0.31074219 * 5120; time = 0.1026s; samplesPerSecond = 49899.3
01/08/2018 04:59:48:  Epoch[ 4 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 0.97195587 * 5120; err = 0.29687500 * 5120; time = 0.0987s; samplesPerSecond = 51851.9
01/08/2018 04:59:48: Finished Epoch[ 4 of 4]: [Training] ce = 1.00270529 * 81920; err = 0.31278076 * 81920; totalSamplesSeen = 327680; learningRatePerSample = 0.003125; epochTime=1.88869s
01/08/2018 04:59:48: SGD: Saving checkpoint model '/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/models/cntkSpeech'

01/08/2018 04:59:48: Action "train" complete.


01/08/2018 04:59:48: ##############################################################################
01/08/2018 04:59:48: #                                                                            #
01/08/2018 04:59:48: # replaceCriterionNode command (edit action)                                 #
01/08/2018 04:59:48: #                                                                            #
01/08/2018 04:59:48: ##############################################################################


01/08/2018 04:59:48: Action "edit" complete.


01/08/2018 04:59:48: ##############################################################################
01/08/2018 04:59:48: #                                                                            #
01/08/2018 04:59:48: # sequenceTrain command (train action)                                       #
01/08/2018 04:59:48: #                                                                            #
01/08/2018 04:59:48: ##############################################################################

01/08/2018 04:59:48: 
Starting from checkpoint. Loading network from '/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/models/cntkSpeech.sequence.0'.
NDLBuilder Using GPU 0
simplesenonehmm: reading '/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData/model.overalltying', '/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData/state.list', '/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData/model.transprob'
simplesenonehmm: 83253 units with 45 unique HMMs, 132 tied states, and 45 trans matrices read
reading script file /tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData/glob_0000.scp ... 948 entries
trainlayer: OOV-exclusion code enabled, but no unigram specified to derive the word set from, so you won't get OOV exclusion
total 132 state names in state list /tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData/state.list
htkmlfreader: reading MLF file /tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData/glob_0000.mlf ... total 948 entries
archive: opening 80 lattice-archive TOC files ('/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/TestData/CY2SCH010061231_1369712653.numden.lats.toc' etc.).................................................................................. 923 total lattices referenced in 80 archive files
. [no lattice for An4/454/454/an70-meht-b]....... [no lattice for An4/89/89/an6-fjmd-b].. [no lattice for An4/683/683/an364-mmkw-b].. [no lattice for An4/476/476/an256-mewl-b].... [no lattice for An4/2/2/an253-fash-b]...............................................................................feature set 0: 250814 frames in 923 out of 948 utterances
minibatchutterancesource: out of 948 files, 0 files not found in label set and 25 have no lattice
label set 0: 129 classes
minibatchutterancesource: 923 utterances grouped into 3 chunks, av. chunk size: 307.7 utterances, 83604.7 frames
01/08/2018 04:59:48: 
Model has 29 nodes. Using GPU 0.

01/08/2018 04:59:48: Training criterion:   ce = SequenceWithSoftmax
01/08/2018 04:59:48: Evaluation criterion: err = ClassificationError

01/08/2018 04:59:48: Training 779396 parameters in 8 out of 8 parameter tensors and 21 nodes with gradient:

01/08/2018 04:59:48: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
01/08/2018 04:59:48: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
01/08/2018 04:59:48: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
01/08/2018 04:59:48: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
01/08/2018 04:59:48: 	Node 'HL3.W' (LearnableParameter operation) : [512 x 512]
01/08/2018 04:59:48: 	Node 'HL3.b' (LearnableParameter operation) : [512 x 1]
01/08/2018 04:59:48: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
01/08/2018 04:59:48: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

01/08/2018 04:59:48: No PreCompute nodes found, or all already computed. Skipping pre-computation step.
Setting Hsmoothing weight to 0.95 and frame-dropping threshhold to 1e-10
Setting SeqGammar-related parameters: amf=14.00, lmf=14.00, wp=0.00, bMMIFactor=0.00, usesMBR=false

01/08/2018 04:59:48: Starting Epoch 1: learning rate per sample = 0.000002  effective momentum = 0.995898  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

01/08/2018 05:00:08: Starting minibatch loop.
dengamma value 1.012012
dengamma value 1.087180
dengamma value 1.022116
dengamma value 1.071730
dengamma value 1.037307
dengamma value 1.068449
dengamma value 1.022342
dengamma value 1.013674
dengamma value 1.148836
dengamma value 0.950760
dengamma value 1.001615
dengamma value 1.057072
dengamma value 1.041703
dengamma value 1.068045
dengamma value 1.033457
dengamma value 1.080927
dengamma value 1.061708
dengamma value 1.077692
dengamma value 0.997829
dengamma value 1.039054
dengamma value 1.050755
dengamma value 1.070974
01/08/2018 05:00:15:  Epoch[ 1 of 3]-Minibatch[   1-  10, 0.12%]: ce = 0.08655488 * 5566; err = 0.32860223 * 5566; time = 6.9142s; samplesPerSecond = 805.0
dengamma value 0.996455
dengamma value 1.044320
dengamma value 1.032099
dengamma value 1.019754
dengamma value 1.022265
dengamma value 1.058904
dengamma value 1.117238
dengamma value 1.040625
dengamma value 1.028245
dengamma value 0.989159
dengamma value 0.993489
dengamma value 1.061652
dengamma value 1.032575
dengamma value 0.994623
dengamma value 1.042659
dengamma value 0.993337
dengamma value 1.003423
dengamma value 1.050600
dengamma value 1.018872
dengamma value 1.087348
dengamma value 1.030570
dengamma value 1.072098
dengamma value 1.047004
dengamma value 1.192866
dengamma value 1.061003
dengamma value 1.056849
01/08/2018 05:00:16:  Epoch[ 1 of 3]-Minibatch[  11-  20, 0.24%]: ce = 0.08023573 * 7398; err = 0.31021898 * 7398; time = 1.0323s; samplesPerSecond = 7166.5
dengamma value 1.104988
dengamma value 0.990668
dengamma value 1.035369
dengamma value 0.979018
dengamma value 1.044127
dengamma value 1.058721
dengamma value 1.077221
dengamma value 1.062522
dengamma value 1.094841
dengamma value 1.087912
dengamma value 1.018004
dengamma value 1.071051
dengamma value 1.042829
dengamma value 0.941600
dengamma value 1.094019
dengamma value 1.036518
dengamma value 1.104592
dengamma value 1.013517
dengamma value 1.019279
dengamma value 1.052925
dengamma value 1.043087
dengamma value 1.038637
dengamma value 1.036010
dengamma value 1.111078
dengamma value 1.094766
01/08/2018 05:00:17:  Epoch[ 1 of 3]-Minibatch[  21-  30, 0.37%]: ce = 0.07889038 * 6300; err = 0.33634921 * 6300; time = 0.8858s; samplesPerSecond = 7112.2
dengamma value 1.099458
dengamma value 1.188036
dengamma value 1.062819
dengamma value 1.052703
dengamma value 1.029209
dengamma value 0.994804
dengamma value 0.995904
dengamma value 1.051781
dengamma value 1.110016
dengamma value 1.025212
dengamma value 1.039427
dengamma value 1.070104
dengamma value 1.084252
dengamma value 1.037866
dengamma value 1.107767
dengamma value 1.049297
dengamma value 0.998075
dengamma value 1.040667
dengamma value 1.016512
dengamma value 0.982668
dengamma value 0.932219
dengamma value 1.047338
01/08/2018 05:00:18:  Epoch[ 1 of 3]-Minibatch[  31-  40, 0.49%]: ce = 0.08027329 * 5636; err = 0.32008517 * 5636; time = 0.7711s; samplesPerSecond = 7309.1
dengamma value 1.037836
dengamma value 1.028027
dengamma value 1.039708
dengamma value 1.060534
dengamma value 1.051816
dengamma value 1.074617
dengamma value 1.060935
dengamma value 1.025414
dengamma value 0.942736
dengamma value 1.034591
dengamma value 1.014542
dengamma value 1.053528
dengamma value 1.046108
dengamma value 0.950258
dengamma value 1.050313
dengamma value 0.982782
dengamma value 1.087317
dengamma value 1.017036
dengamma value 1.057341
dengamma value 0.967332
01/08/2018 05:00:19:  Epoch[ 1 of 3]-Minibatch[  41-  50, 0.61%]: ce = 0.08160371 * 6970; err = 0.33758967 * 6970; time = 0.9959s; samplesPerSecond = 6998.4
dengamma value 1.060136
dengamma value 1.030291
dengamma value 1.051141
dengamma value 1.040629
dengamma value 1.060541
dengamma value 1.060817
dengamma value 1.046992
dengamma value 1.066482
dengamma value 1.052687
dengamma value 1.049015
dengamma value 1.007731
dengamma value 1.056739
dengamma value 1.029194
dengamma value 1.055028
dengamma value 1.012405
dengamma value 1.087851
dengamma value 1.047854
dengamma value 0.993461
dengamma value 1.126197
dengamma value 1.004295
dengamma value 1.000727
dengamma value 1.063041
01/08/2018 05:00:20:  Epoch[ 1 of 3]-Minibatch[  51-  60, 0.73%]: ce = 0.08087793 * 6996; err = 0.31646655 * 6996; time = 1.0187s; samplesPerSecond = 6867.6
dengamma value 1.075549
dengamma value 1.019999
dengamma value 1.053811
dengamma value 1.051326
dengamma value 0.994689
dengamma value 1.011477
dengamma value 1.034104
dengamma value 0.977334
dengamma value 1.112193
dengamma value 1.001498
dengamma value 1.041142
dengamma value 0.997612
dengamma value 1.077638
dengamma value 1.091157
dengamma value 1.097614
dengamma value 0.979149
dengamma value 0.993519
dengamma value 1.044204
dengamma value 1.027778
dengamma value 1.123037
dengamma value 1.026375
dengamma value 1.059629
dengamma value 1.083138
dengamma value 1.015841
dengamma value 1.009199
01/08/2018 05:00:21:  Epoch[ 1 of 3]-Minibatch[  61-  70, 0.85%]: ce = 0.08600312 * 6180; err = 0.33171521 * 6180; time = 0.8848s; samplesPerSecond = 6984.5
dengamma value 1.043087
dengamma value 1.060695
dengamma value 1.133168
dengamma value 1.002898
dengamma value 1.072520
dengamma value 1.037385
dengamma value 0.989507
dengamma value 1.058915
dengamma value 1.031753
dengamma value 1.043151
dengamma value 1.031351
dengamma value 1.036116
dengamma value 1.089213
dengamma value 0.970682
dengamma value 1.110788
dengamma value 1.047752
dengamma value 1.044100
dengamma value 1.109448
dengamma value 1.050631
dengamma value 1.121895
01/08/2018 05:00:21:  Epoch[ 1 of 3]-Minibatch[  71-  80, 0.98%]: ce = 0.08468580 * 4860; err = 0.33106996 * 4860; time = 0.6859s; samplesPerSecond = 7085.7
dengamma value 1.029638
dengamma value 0.966383
dengamma value 1.017411
dengamma value 1.064938
dengamma value 1.028244
dengamma value 1.074713
dengamma value 1.002401
dengamma value 1.072079
dengamma value 1.018185
dengamma value 0.992575
dengamma value 1.032718
dengamma value 0.946155
dengamma value 1.027724
dengamma value 1.073695
dengamma value 1.041966
dengamma value 1.094695
dengamma value 1.059544
dengamma value 1.041907
dengamma value 1.036495
dengamma value 1.014408
dengamma value 1.101968
dengamma value 1.064950
01/08/2018 05:00:22:  Epoch[ 1 of 3]-Minibatch[  81-  90, 1.10%]: ce = 0.07725165 * 6046; err = 0.32583526 * 6046; time = 0.8648s; samplesPerSecond = 6991.3
dengamma value 1.041775
dengamma value 1.001476
dengamma value 1.010233
dengamma value 0.962684
dengamma value 1.019743
dengamma value 1.096266
dengamma value 1.032751
dengamma value 0.999943
dengamma value 1.030942
dengamma value 1.054469
dengamma value 0.990395
dengamma value 1.030501
dengamma value 1.047916
dengamma value 1.079602
dengamma value 0.992728
dengamma value 1.050513
dengamma value 1.004785
dengamma value 1.010053
dengamma value 1.001834
dengamma value 1.005318
dengamma value 0.991556
dengamma value 1.058391
dengamma value 1.022594
dengamma value 1.033818
01/08/2018 05:00:23:  Epoch[ 1 of 3]-Minibatch[  91- 100, 1.22%]: ce = 0.08675925 * 6942; err = 0.34067992 * 6942; time = 0.9415s; samplesPerSecond = 7373.5
dengamma value 1.015942
dengamma value 1.039853
dengamma value 1.007565
dengamma value 0.932433
dengamma value 1.068914
dengamma value 1.085469
dengamma value 1.134563
dengamma value 1.015731
dengamma value 1.029028
dengamma value 1.107273
dengamma value 1.064041
dengamma value 1.007279
dengamma value 1.054998
dengamma value 1.023920
dengamma value 1.107356
dengamma value 1.012895
dengamma value 1.040466
dengamma value 1.057855
dengamma value 1.008893
dengamma value 0.999551
dengamma value 0.978126
dengamma value 1.064539
dengamma value 1.062115
01/08/2018 05:00:24:  Epoch[ 1 of 3]-Minibatch[ 101- 110, 1.34%]: ce = 0.08851550 * 5784; err = 0.32814661 * 5784; time = 0.7658s; samplesPerSecond = 7552.8
dengamma value 1.072372
dengamma value 1.074623
dengamma value 1.012300
dengamma value 1.011121
dengamma value 1.123489
dengamma value 0.998681
dengamma value 0.962504
dengamma value 0.959515
dengamma value 0.940330
dengamma value 1.032837
dengamma value 1.033413
dengamma value 0.978494
dengamma value 1.061632
dengamma value 1.030846
dengamma value 1.062563
dengamma value 0.987564
dengamma value 1.016833
dengamma value 1.042698
dengamma value 1.064179
dengamma value 0.980856
dengamma value 1.098526
01/08/2018 05:00:25:  Epoch[ 1 of 3]-Minibatch[ 111- 120, 1.46%]: ce = 0.08885892 * 6258; err = 0.33828699 * 6258; time = 0.8409s; samplesPerSecond = 7442.4
dengamma value 1.099933
dengamma value 1.076895
dengamma value 1.065816
dengamma value 1.074247
dengamma value 1.019463
dengamma value 1.114041
dengamma value 1.070192
dengamma value 1.017231
dengamma value 1.035979
dengamma value 1.016786
dengamma value 1.025476
dengamma value 1.062421
dengamma value 1.041432
dengamma value 1.076558
dengamma value 0.964266
dengamma value 1.005863
dengamma value 1.070800
dengamma value 1.011901
dengamma value 1.100915
dengamma value 1.003041
dengamma value 1.023316
dengamma value 0.967115
01/08/2018 05:00:26:  Epoch[ 1 of 3]-Minibatch[ 121- 130, 1.59%]: ce = 0.08330009 * 6116; err = 0.31932636 * 6116; time = 0.8531s; samplesPerSecond = 7169.0
dengamma value 1.040954
dengamma value 1.047457
dengamma value 1.001838
dengamma value 1.047483
01/08/2018 05:00:26: Finished Epoch[ 1 of 3]: [Training] ce = 0.08348277 * 82574; err = 0.32756073 * 82574; totalSamplesSeen = 82574; learningRatePerSample = 2e-06; epochTime=37.6221s
01/08/2018 05:00:26: SGD: Saving checkpoint model '/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/models/cntkSpeech.sequence.1'

01/08/2018 05:00:26: Starting Epoch 2: learning rate per sample = 0.000002  effective momentum = 0.995898  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 82146), data subset 0 of 1, with 1 datapasses

01/08/2018 05:00:26: Starting minibatch loop.
dengamma value 1.028162
dengamma value 1.000749
dengamma value 0.985048
dengamma value 1.069680
dengamma value 1.068763
dengamma value 1.005524
dengamma value 1.055002
dengamma value 1.012531
dengamma value 1.026274
dengamma value 1.026706
dengamma value 1.039425
dengamma value 1.001626
dengamma value 1.048758
dengamma value 1.090603
dengamma value 0.967304
dengamma value 0.995885
dengamma value 1.018548
dengamma value 1.019760
dengamma value 1.062275
dengamma value 1.042650
dengamma value 1.060187
dengamma value 1.083872
01/08/2018 05:00:27:  Epoch[ 2 of 3]-Minibatch[   1-  10, 0.12%]: ce = 0.08384530 * 5826; err = 0.33281840 * 5826; time = 0.8254s; samplesPerSecond = 7058.6
dengamma value 1.060452
dengamma value 1.098212
dengamma value 1.085399
dengamma value 1.048861
dengamma value 1.045005
dengamma value 1.006995
dengamma value 1.086377
dengamma value 1.083350
dengamma value 1.091276
dengamma value 1.048653
dengamma value 1.034582
dengamma value 0.956167
dengamma value 1.078462
dengamma value 1.076423
dengamma value 1.036555
dengamma value 1.042300
dengamma value 1.034658
dengamma value 1.027498
dengamma value 1.048803
dengamma value 1.015332
01/08/2018 05:00:28:  Epoch[ 2 of 3]-Minibatch[  11-  20, 0.24%]: ce = 0.08018141 * 6380; err = 0.31394984 * 6380; time = 0.9358s; samplesPerSecond = 6817.6
dengamma value 1.098551
dengamma value 1.019086
dengamma value 1.116961
dengamma value 0.944254
dengamma value 1.026758
dengamma value 1.071380
dengamma value 1.110151
dengamma value 1.037853
dengamma value 1.070500
dengamma value 1.011806
dengamma value 0.991621
dengamma value 1.084383
dengamma value 1.019003
dengamma value 1.053074
dengamma value 1.016184
dengamma value 1.016897
dengamma value 1.054544
dengamma value 1.071215
dengamma value 1.034109
dengamma value 1.039155
dengamma value 1.082859
dengamma value 1.057524
dengamma value 0.998483
01/08/2018 05:00:29:  Epoch[ 2 of 3]-Minibatch[  21-  30, 0.37%]: ce = 0.07810651 * 6574; err = 0.32020079 * 6574; time = 0.9917s; samplesPerSecond = 6628.8
dengamma value 1.077011
dengamma value 1.050448
dengamma value 1.055005
dengamma value 1.056396
dengamma value 0.930691
dengamma value 0.959766
dengamma value 1.126942
dengamma value 1.078597
dengamma value 1.030596
dengamma value 1.027002
dengamma value 1.050359
dengamma value 0.970122
dengamma value 1.054725
dengamma value 1.006074
dengamma value 0.962304
dengamma value 1.082271
dengamma value 1.064090
dengamma value 1.094649
dengamma value 0.994525
dengamma value 0.989146
dengamma value 1.076173
dengamma value 1.119426
dengamma value 1.009267
01/08/2018 05:00:30:  Epoch[ 2 of 3]-Minibatch[  31-  40, 0.49%]: ce = 0.08763376 * 6324; err = 0.33222644 * 6324; time = 0.8561s; samplesPerSecond = 7387.3
dengamma value 0.959217
dengamma value 0.940341
dengamma value 0.936884
dengamma value 1.053080
dengamma value 1.075730
dengamma value 1.105936
dengamma value 1.044491
dengamma value 1.146869
dengamma value 1.033105
dengamma value 0.980770
dengamma value 1.008945
dengamma value 1.012118
dengamma value 0.957894
dengamma value 1.099003
dengamma value 1.043185
dengamma value 0.994070
dengamma value 0.943640
dengamma value 0.994691
dengamma value 1.017901
dengamma value 1.047139
01/08/2018 05:00:30:  Epoch[ 2 of 3]-Minibatch[  41-  50, 0.61%]: ce = 0.09121770 * 4800; err = 0.35916667 * 4800; time = 0.6409s; samplesPerSecond = 7489.0
dengamma value 0.994378
dengamma value 1.049854
dengamma value 1.047574
dengamma value 1.046682
dengamma value 1.041410
dengamma value 1.117760
dengamma value 1.097998
dengamma value 1.022400
dengamma value 1.068992
dengamma value 1.006407
dengamma value 1.072963
dengamma value 1.017451
dengamma value 0.984636
dengamma value 0.998748
dengamma value 1.061846
dengamma value 1.027188
dengamma value 1.029141
dengamma value 1.016491
dengamma value 1.011817
dengamma value 1.042910
dengamma value 1.017297
dengamma value 1.055379
01/08/2018 05:00:31:  Epoch[ 2 of 3]-Minibatch[  51-  60, 0.73%]: ce = 0.08173046 * 6176; err = 0.34553109 * 6176; time = 0.8344s; samplesPerSecond = 7401.8
dengamma value 1.087938
dengamma value 1.056922
dengamma value 1.066305
dengamma value 0.985157
dengamma value 1.078067
dengamma value 1.046227
dengamma value 1.087034
dengamma value 0.961369
dengamma value 1.066922
dengamma value 1.035862
dengamma value 1.065924
dengamma value 1.021172
dengamma value 1.062150
dengamma value 1.001294
dengamma value 1.067775
dengamma value 1.043032
dengamma value 1.090573
dengamma value 1.140171
dengamma value 1.036839
dengamma value 0.960914
dengamma value 1.082227
dengamma value 1.051270
dengamma value 1.043380
01/08/2018 05:00:32:  Epoch[ 2 of 3]-Minibatch[  61-  70, 0.85%]: ce = 0.08976866 * 5534; err = 0.30972172 * 5534; time = 0.8289s; samplesPerSecond = 6676.6
dengamma value 1.064300
dengamma value 1.002540
dengamma value 0.985373
dengamma value 1.036648
dengamma value 1.109148
dengamma value 0.958150
dengamma value 1.072689
dengamma value 1.063475
dengamma value 1.051308
dengamma value 1.050433
dengamma value 1.099083
dengamma value 1.109549
dengamma value 1.053554
dengamma value 1.074900
dengamma value 1.043269
dengamma value 1.031603
dengamma value 1.045897
dengamma value 0.990040
dengamma value 1.069206
dengamma value 1.033670
dengamma value 0.996517
dengamma value 1.067711
01/08/2018 05:00:33:  Epoch[ 2 of 3]-Minibatch[  71-  80, 0.98%]: ce = 0.08287801 * 5936; err = 0.30811995 * 5936; time = 0.9303s; samplesPerSecond = 6380.9
dengamma value 0.917860
dengamma value 1.071469
dengamma value 1.069430
dengamma value 1.056340
dengamma value 1.072937
dengamma value 1.009601
dengamma value 1.079135
dengamma value 1.032388
dengamma value 1.030378
dengamma value 1.063679
dengamma value 0.904643
dengamma value 1.061990
dengamma value 1.120163
dengamma value 1.073211
dengamma value 1.005450
dengamma value 1.084971
dengamma value 1.086336
dengamma value 1.082422
dengamma value 1.095449
dengamma value 1.098342
dengamma value 1.059455
01/08/2018 05:00:34:  Epoch[ 2 of 3]-Minibatch[  81-  90, 1.10%]: ce = 0.08283378 * 5248; err = 0.31821646 * 5248; time = 0.7531s; samplesPerSecond = 6968.4
dengamma value 1.043380
dengamma value 1.036916
dengamma value 1.056993
dengamma value 1.021712
dengamma value 1.059318
dengamma value 1.063351
dengamma value 1.045733
dengamma value 0.990045
dengamma value 1.057704
dengamma value 1.036713
dengamma value 1.113947
dengamma value 1.081324
dengamma value 0.978271
dengamma value 1.069405
dengamma value 1.095186
dengamma value 1.025498
dengamma value 1.093578
dengamma value 1.104031
dengamma value 1.052968
dengamma value 1.029299
dengamma value 1.004395
dengamma value 1.054941
dengamma value 1.047438
dengamma value 1.060550
dengamma value 1.026136
dengamma value 1.066897
01/08/2018 05:00:35:  Epoch[ 2 of 3]-Minibatch[  91- 100, 1.22%]: ce = 0.08198595 * 6888; err = 0.31155633 * 6888; time = 0.9981s; samplesPerSecond = 6901.0
dengamma value 1.045445
dengamma value 1.069412
dengamma value 1.031373
dengamma value 1.046173
dengamma value 1.022170
dengamma value 1.032806
dengamma value 1.013829
dengamma value 1.090520
dengamma value 1.069849
dengamma value 1.022711
dengamma value 1.036457
dengamma value 1.089586
dengamma value 1.072234
dengamma value 1.006733
dengamma value 1.093909
dengamma value 1.008151
dengamma value 1.006160
dengamma value 1.113210
dengamma value 1.052631
dengamma value 1.030073
dengamma value 1.020807
dengamma value 1.020389
dengamma value 0.978808
dengamma value 1.035493
01/08/2018 05:00:36:  Epoch[ 2 of 3]-Minibatch[ 101- 110, 1.34%]: ce = 0.08607866 * 6572; err = 0.33414486 * 6572; time = 0.8975s; samplesPerSecond = 7322.4
dengamma value 0.998438
dengamma value 1.073449
dengamma value 1.003841
dengamma value 1.087101
dengamma value 1.038419
dengamma value 1.008995
dengamma value 1.004203
dengamma value 1.063094
dengamma value 1.033689
dengamma value 1.005804
dengamma value 1.058146
dengamma value 1.060388
dengamma value 1.060750
dengamma value 1.046433
dengamma value 1.027616
dengamma value 1.029518
dengamma value 1.019679
dengamma value 1.102126
dengamma value 0.996106
dengamma value 1.050253
dengamma value 1.047915
dengamma value 1.129999
dengamma value 1.067716
dengamma value 1.027554
01/08/2018 05:00:37:  Epoch[ 2 of 3]-Minibatch[ 111- 120, 1.46%]: ce = 0.08691790 * 6622; err = 0.31199034 * 6622; time = 0.9970s; samplesPerSecond = 6641.9
dengamma value 1.025426
dengamma value 1.090093
dengamma value 1.016794
dengamma value 0.982866
dengamma value 1.035480
dengamma value 1.014890
dengamma value 0.951742
dengamma value 0.989221
dengamma value 0.941080
dengamma value 1.049111
dengamma value 1.071354
dengamma value 1.135409
dengamma value 1.092682
dengamma value 1.093532
dengamma value 1.023659
dengamma value 1.040390
dengamma value 0.998715
dengamma value 1.042984
dengamma value 1.028993
dengamma value 0.967911
dengamma value 1.041735
dengamma value 1.091733
dengamma value 1.033576
01/08/2018 05:00:37:  Epoch[ 2 of 3]-Minibatch[ 121- 130, 1.59%]: ce = 0.08757866 * 5824; err = 0.31936813 * 5824; time = 0.7797s; samplesPerSecond = 7469.1
dengamma value 0.972602
dengamma value 1.036434
dengamma value 1.103766
dengamma value 0.964817
dengamma value 1.015265
dengamma value 1.089995
dengamma value 1.058848
dengamma value 1.152190
dengamma value 1.039549
01/08/2018 05:00:38: Finished Epoch[ 2 of 3]: [Training] ce = 0.08441044 * 81776; err = 0.32311436 * 81776; totalSamplesSeen = 164350; learningRatePerSample = 2e-06; epochTime=11.739s
01/08/2018 05:00:38: SGD: Saving checkpoint model '/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/models/cntkSpeech.sequence.2'

01/08/2018 05:00:38: Starting Epoch 3: learning rate per sample = 0.000002  effective momentum = 0.995898  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 2: frames [163840..245760] (first utterance at frame 163922), data subset 0 of 1, with 1 datapasses

01/08/2018 05:00:38: Starting minibatch loop.
dengamma value 1.084253
dengamma value 1.028605
dengamma value 1.062441
dengamma value 1.081738
dengamma value 1.087205
dengamma value 1.001017
dengamma value 1.033804
dengamma value 0.999081
dengamma value 1.011620
dengamma value 1.004229
dengamma value 1.042330
dengamma value 1.040782
dengamma value 1.030027
dengamma value 1.059908
dengamma value 1.053160
dengamma value 1.124262
dengamma value 1.012493
dengamma value 1.110548
dengamma value 1.024697
dengamma value 1.072077
dengamma value 0.997024
dengamma value 1.050212
dengamma value 1.096075
01/08/2018 05:00:39:  Epoch[ 3 of 3]-Minibatch[   1-  10, 0.12%]: ce = 0.08300957 * 5074; err = 0.32558140 * 5074; time = 0.7577s; samplesPerSecond = 6697.0
dengamma value 1.007282
dengamma value 1.092618
dengamma value 1.058780
dengamma value 1.061018
dengamma value 0.990368
dengamma value 0.985479
dengamma value 0.995563
dengamma value 0.993087
dengamma value 1.102775
dengamma value 1.069091
dengamma value 1.034297
dengamma value 1.025694
dengamma value 1.038543
dengamma value 1.024952
dengamma value 1.089994
dengamma value 1.088597
dengamma value 1.028873
dengamma value 1.042191
dengamma value 1.077866
dengamma value 0.960319
dengamma value 1.041474
dengamma value 1.027602
01/08/2018 05:00:40:  Epoch[ 3 of 3]-Minibatch[  11-  20, 0.24%]: ce = 0.08099654 * 7136; err = 0.31558296 * 7136; time = 0.9743s; samplesPerSecond = 7324.3
dengamma value 1.094257
dengamma value 1.016346
dengamma value 0.988887
dengamma value 1.009622
dengamma value 1.072339
dengamma value 1.028851
dengamma value 1.112198
dengamma value 0.985163
dengamma value 1.017275
dengamma value 1.051574
dengamma value 1.084491
dengamma value 1.049200
dengamma value 1.094560
dengamma value 1.011757
dengamma value 1.063842
dengamma value 1.025059
dengamma value 1.045552
dengamma value 1.015721
dengamma value 1.105887
dengamma value 1.109283
dengamma value 1.025690
dengamma value 1.004284
dengamma value 1.007526
01/08/2018 05:00:40:  Epoch[ 3 of 3]-Minibatch[  21-  30, 0.37%]: ce = 0.09269690 * 5504; err = 0.33884448 * 5504; time = 0.8128s; samplesPerSecond = 6771.9
dengamma value 1.050683
dengamma value 1.055043
dengamma value 1.055134
dengamma value 1.077124
dengamma value 1.060735
dengamma value 0.997794
dengamma value 1.061883
dengamma value 1.079686
dengamma value 1.022012
dengamma value 1.115434
dengamma value 1.045081
dengamma value 1.054144
dengamma value 1.047343
dengamma value 1.094048
dengamma value 0.978505
dengamma value 1.052597
dengamma value 1.003642
dengamma value 1.017311
dengamma value 0.940632
dengamma value 1.132268
dengamma value 1.054808
01/08/2018 05:00:41:  Epoch[ 3 of 3]-Minibatch[  31-  40, 0.49%]: ce = 0.08412086 * 6028; err = 0.32282681 * 6028; time = 0.8822s; samplesPerSecond = 6832.9
dengamma value 1.054833
dengamma value 1.093141
dengamma value 1.057313
dengamma value 1.063537
dengamma value 0.986100
dengamma value 0.978656
dengamma value 1.035908
dengamma value 0.996523
dengamma value 1.038121
dengamma value 1.108674
dengamma value 1.064510
dengamma value 1.027397
dengamma value 1.065309
dengamma value 1.058254
dengamma value 1.050187
dengamma value 1.011454
dengamma value 1.018331
dengamma value 1.142646
dengamma value 1.014342
dengamma value 1.044579
dengamma value 1.028866
01/08/2018 05:00:42:  Epoch[ 3 of 3]-Minibatch[  41-  50, 0.61%]: ce = 0.08500887 * 6028; err = 0.32614466 * 6028; time = 0.8142s; samplesPerSecond = 7403.6
dengamma value 1.022799
dengamma value 1.045421
dengamma value 1.020124
dengamma value 0.991797
dengamma value 1.051695
dengamma value 1.102593
dengamma value 1.090530
dengamma value 1.065616
dengamma value 0.968689
dengamma value 1.165761
dengamma value 0.992939
dengamma value 0.987977
dengamma value 1.057049
dengamma value 1.038980
dengamma value 1.039704
dengamma value 1.078651
dengamma value 0.990410
dengamma value 0.981781
dengamma value 1.054310
dengamma value 1.019209
dengamma value 1.052183
dengamma value 1.041306
dengamma value 1.008954
dengamma value 1.016922
01/08/2018 05:00:43:  Epoch[ 3 of 3]-Minibatch[  51-  60, 0.73%]: ce = 0.08529569 * 6782; err = 0.32630492 * 6782; time = 0.9229s; samplesPerSecond = 7348.5
dengamma value 1.064054
dengamma value 1.049082
dengamma value 1.104684
dengamma value 1.019940
dengamma value 1.095451
dengamma value 1.045999
dengamma value 1.091496
dengamma value 1.099513
dengamma value 1.076978
dengamma value 1.014367
dengamma value 1.073992
dengamma value 1.095660
dengamma value 0.996166
dengamma value 1.128519
dengamma value 1.123444
dengamma value 1.004168
dengamma value 1.050457
dengamma value 1.116037
dengamma value 1.064486
dengamma value 0.989705
dengamma value 1.019877
01/08/2018 05:00:44:  Epoch[ 3 of 3]-Minibatch[  61-  70, 0.85%]: ce = 0.07851903 * 5458; err = 0.29388054 * 5458; time = 0.8403s; samplesPerSecond = 6495.0
dengamma value 1.059652
dengamma value 1.022118
dengamma value 1.081723
dengamma value 1.064197
dengamma value 1.214551
dengamma value 1.093861
dengamma value 0.974823
dengamma value 1.068808
dengamma value 1.080568
dengamma value 1.043009
dengamma value 1.044542
dengamma value 1.076490
dengamma value 1.123328
dengamma value 1.148237
dengamma value 1.034293
dengamma value 1.070244
dengamma value 1.018071
dengamma value 1.016881
dengamma value 1.007035
dengamma value 1.109150
dengamma value 1.073673
dengamma value 1.113990
dengamma value 1.088085
dengamma value 1.095555
dengamma value 1.010897
01/08/2018 05:00:45:  Epoch[ 3 of 3]-Minibatch[  71-  80, 0.98%]: ce = 0.07968477 * 6610; err = 0.29062027 * 6610; time = 0.9448s; samplesPerSecond = 6996.2
dengamma value 1.066712
dengamma value 1.061044
dengamma value 1.104056
dengamma value 1.069869
dengamma value 1.062833
dengamma value 0.971857
dengamma value 1.020864
dengamma value 1.069101
dengamma value 1.077943
dengamma value 1.060667
dengamma value 1.028904
dengamma value 0.952513
dengamma value 1.114280
dengamma value 1.098547
dengamma value 1.009857
dengamma value 1.037390
dengamma value 0.908577
dengamma value 1.056258
dengamma value 1.110889
dengamma value 1.050528
dengamma value 1.023042
dengamma value 1.082115
dengamma value 1.034973
01/08/2018 05:00:46:  Epoch[ 3 of 3]-Minibatch[  81-  90, 1.10%]: ce = 0.08506299 * 5854; err = 0.31568159 * 5854; time = 0.7997s; samplesPerSecond = 7320.0
dengamma value 1.055883
dengamma value 1.123228
dengamma value 1.096702
dengamma value 0.877785
dengamma value 1.042769
dengamma value 1.063701
dengamma value 0.974222
dengamma value 1.079643
dengamma value 1.018121
dengamma value 1.016394
dengamma value 1.027971
dengamma value 1.006676
dengamma value 1.096910
dengamma value 1.050236
dengamma value 1.100623
dengamma value 1.079785
dengamma value 1.046448
dengamma value 1.098962
dengamma value 1.033907
dengamma value 0.971004
dengamma value 1.030080
dengamma value 1.061246
dengamma value 1.024059
01/08/2018 05:00:46:  Epoch[ 3 of 3]-Minibatch[  91- 100, 1.22%]: ce = 0.08888839 * 4674; err = 0.33097989 * 4674; time = 0.6751s; samplesPerSecond = 6923.2
dengamma value 0.995003
dengamma value 1.027413
dengamma value 1.055511
dengamma value 1.070667
dengamma value 1.030278
dengamma value 1.071882
dengamma value 1.041616
dengamma value 1.000360
dengamma value 1.113958
dengamma value 1.038631
dengamma value 1.032350
dengamma value 1.057001
dengamma value 1.061291
dengamma value 1.003505
dengamma value 0.915331
dengamma value 0.976226
dengamma value 1.002378
dengamma value 1.048060
dengamma value 1.029371
dengamma value 0.978648
dengamma value 1.075851
01/08/2018 05:00:47:  Epoch[ 3 of 3]-Minibatch[ 101- 110, 1.34%]: ce = 0.08176953 * 6248; err = 0.32810499 * 6248; time = 0.8779s; samplesPerSecond = 7117.0
dengamma value 0.969108
dengamma value 1.046409
dengamma value 1.050709
dengamma value 1.063980
dengamma value 1.135071
dengamma value 1.026583
dengamma value 1.048966
dengamma value 1.046966
dengamma value 1.086821
dengamma value 1.007935
dengamma value 1.000955
dengamma value 1.015057
dengamma value 1.048132
dengamma value 1.055581
dengamma value 0.986386
dengamma value 1.082918
dengamma value 1.109494
dengamma value 1.025734
dengamma value 1.040406
dengamma value 1.144299
dengamma value 1.095645
dengamma value 1.049240
dengamma value 1.071901
01/08/2018 05:00:48:  Epoch[ 3 of 3]-Minibatch[ 111- 120, 1.46%]: ce = 0.07837878 * 7094; err = 0.31420919 * 7094; time = 0.9866s; samplesPerSecond = 7190.4
dengamma value 1.049079
dengamma value 1.072989
dengamma value 1.054483
dengamma value 1.054633
dengamma value 1.041276
dengamma value 1.049127
dengamma value 1.050849
dengamma value 0.975031
dengamma value 0.991145
dengamma value 1.050516
dengamma value 1.061593
dengamma value 1.030298
dengamma value 1.010147
dengamma value 1.073787
dengamma value 0.995785
dengamma value 1.091637
dengamma value 1.055274
dengamma value 1.051714
dengamma value 1.030882
dengamma value 1.040881
dengamma value 1.058206
dengamma value 1.035061
01/08/2018 05:00:49:  Epoch[ 3 of 3]-Minibatch[ 121- 130, 1.59%]: ce = 0.08649145 * 6246; err = 0.31284022 * 6246; time = 0.9148s; samplesPerSecond = 6827.6
dengamma value 1.002956
dengamma value 1.050704
dengamma value 1.041014
dengamma value 1.073822
dengamma value 1.034212
dengamma value 0.964750
dengamma value 1.003074
dengamma value 1.124020
dengamma value 1.068041
dengamma value 0.981262
dengamma value 0.946396
dengamma value 1.058899
dengamma value 1.058899
01/08/2018 05:00:50: Finished Epoch[ 3 of 3]: [Training] ce = 0.08394595 * 81970; err = 0.31917775 * 81970; totalSamplesSeen = 246320; learningRatePerSample = 2e-06; epochTime=11.6697s
01/08/2018 05:00:50: SGD: Saving checkpoint model '/tmp/cntk-test-20180108044804.549809/Speech/DNN_SequenceTraining@debug_gpu/models/cntkSpeech.sequence'

01/08/2018 05:00:50: Action "train" complete.

01/08/2018 05:00:50: __COMPLETED__